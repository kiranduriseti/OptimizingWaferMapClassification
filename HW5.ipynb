{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "o-bsRg5J_Me8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# OpenCV and Scikit-Image for image manipulation\n",
    "# This code prefers skimage for resize but you can also import and use cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import label, regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, square\n",
    "\n",
    "# Seaborn and Matplotlib for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-Learn and helper functions\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, homogeneity_score, completeness_score\n",
    "\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "\n",
    "FAIL = 2 # failing die\n",
    "PASS = 1 # passing die\n",
    "NO_DIE = 0 # no die\n",
    "RANDOM_SEED = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validating failure type sample sizes for testing and training\n",
    "train_data = np.load(\"data/wafermap_train.npy\", allow_pickle=True)\n",
    "test_data = np.load(\"data/wafermap_test.npy\", allow_pickle=True)\n",
    "\n",
    "df_train = pd.DataFrame({name: train_data[name] for name in train_data.dtype.names})\n",
    "df_test = pd.DataFrame({name: test_data[name] for name in test_data.dtype.names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "IgRL83My_Me_"
   },
   "outputs": [],
   "source": [
    "# TODO: Create dictionary called 'string2int' for converting string to numeric number\n",
    "string2int = {\n",
    "    'Center': 0,\n",
    "    'Donut': 1,\n",
    "    'Edge-Loc': 2,\n",
    "    'Near-full': 3,\n",
    "    'Scratch': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_failure_type(failure_type: str) -> int:\n",
    "    return string2int[failure_type]\n",
    "\n",
    "def resize_wafer_map(wafer_map: np.ndarray, output_shape: tuple=(64, 64)) -> np.ndarray:\n",
    "    return resize(wafer_map, output_shape, order=0, anti_aliasing=False, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that creates dataframe columns to store the return values of the two tasks below using convert_failure_type and resize_wafer_map:\n",
    "#       (1) reshapes the wafer maps as a numpy array of shape (64, 64)\n",
    "#       (2) converts the failureType into numeric values\n",
    "def prepare_data(df: pd.DataFrame, has_labels: bool=True) -> Tuple[np.ndarray, list]:\n",
    "    df[\"waferMap_resized\"] = df[\"waferMap\"].apply(lambda x: resize_wafer_map(x))\n",
    "\n",
    "    if has_labels:\n",
    "        df[\"failureType_num\"] = df[\"failureType\"].apply(convert_failure_type)\n",
    "        labels = df[\"failureType_num\"].tolist()\n",
    "    else:\n",
    "        labels = None\n",
    "\n",
    "    return df, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9rdnCWXV_MfA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      dieSize failureType   lotName trainTestLabel  waferIndex  \\\n",
       " 0      3203.0      Center  lot10006       Training         5.0   \n",
       " 1      1250.0      Center  lot10067       Training         9.0   \n",
       " 2      2393.0      Center  lot10731       Training         9.0   \n",
       " 3      2393.0      Center  lot10742       Training        25.0   \n",
       " 4      2393.0      Center  lot10813       Training        12.0   \n",
       " ...       ...         ...       ...            ...         ...   \n",
       " 2741   1139.0   Near-full  lot15621       Training        25.0   \n",
       " 2742   1389.0   Near-full  lot15785       Training        17.0   \n",
       " 2743   1389.0   Near-full  lot15906       Training         5.0   \n",
       " 2744   2470.0   Near-full  lot26627       Training        15.0   \n",
       " 2745   1791.0   Near-full  lot45652       Training        18.0   \n",
       " \n",
       "                                                waferMap  \\\n",
       " 0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " ...                                                 ...   \n",
       " 2741  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,...   \n",
       " 2742  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 2743  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 2744  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " 2745  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       " \n",
       "                                        waferMap_resized  failureType_num  \n",
       " 0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                0  \n",
       " 1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                0  \n",
       " 2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                0  \n",
       " 3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                0  \n",
       " 4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                0  \n",
       " ...                                                 ...              ...  \n",
       " 2741  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                3  \n",
       " 2742  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                3  \n",
       " 2743  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                3  \n",
       " 2744  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                3  \n",
       " 2745  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                3  \n",
       " \n",
       " [2746 rows x 8 columns],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  ...])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: apply prepare_data\n",
    "prepare_data(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QWtRmkyJg9rp"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement a function that detects connected failing dies using skimage and selects \"one with the largest area(=salient region)\" for each wafer map\n",
    "# Hint: use connectivity=2\n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "def get_salient_region(row: pd.Series) -> np.ndarray:\n",
    "\n",
    "    wafer = row[\"waferMap_resized\"]\n",
    "    fail_mask = (wafer == 2)\n",
    "    labeled_map = label(fail_mask, connectivity=2)\n",
    "    if labeled_map.max() == 0:\n",
    "        return np.zeros_like(wafer)\n",
    "    regions = regionprops(labeled_map)\n",
    "    largest_region = max(regions, key=lambda r: r.area)\n",
    "    salient_region = (labeled_map == largest_region.label).astype(int)\n",
    "\n",
    "    return salient_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_AlsiRlShT9i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Apply get_salient_region to the dataframe and save the results to a new column, and check if the dataframe has new column \"salientRegion\"\n",
    "from skimage.measure import label\n",
    "\n",
    "df_train[\"salientRegion\"] = df_train.apply(get_salient_region, axis=1)\n",
    "\n",
    "df_train[\"salientRegion\"].iloc[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "iFnBlfH6i7nz",
    "outputId": "2b872f64-575b-4d52-a78b-f0cd91b6b243"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAABaCAYAAADOzQbfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEsVJREFUeJztnQd8VFW+x39TMpPeIYGQQiAkEAgltCdBQECB0AVx1bWu+vRZ1nXfW3y29TUFxV2XdVcFdIVFBKTJLlWJJRi6kFBCC4GEkN6T6TPv8z+TiZlkZnJncieZief7+dwPMzf3njn38r/nnvOvEpPJZAKH44VIe7oDHI6rcOHleC1ceDleCxdejtfChZfjtXDh5XgtXHg5XgsXXo7XwoWX47XIhR44U7rUbZ14a/NVfKofh38WDerwN6NShgtL1uD2f9yPCrW/3TakGoPN/YEnK9F36zW4k4PGrS6d58576u0IuaeChdddFD+XimcrUlFv8mWC2ha51IivZm9C5oGlqNb4OWyn/bkWGtMjoRoSAnm9FjGrz4vad87PcNoglZmwYssVVDyTDE1sAG7pgtCk9+lwnMEkwcvHb8e1hhD22RVIqHWRvlDHBaLkiRQRes/xFLpt5NX090f9pCj2WSIBtvmGoHFwCEwm+8+PySRBTnmM1b57EvNRofJH1q04p37fJJdClRyCiqUDW/eF7S+GvF7n9LVwfmbCqw9Xou42s/ASn1396XNbEoLqkBZeji+vJ9n8u84ohb7dKCyTmPBgUh77vOnqMKgNti/LJJVY9UGqMiA4pww+VRqXronTy6cNmn7+aBoWCnVsAPvuIzViSr8bdo+PVKowKrzc7t93FA7B96WxiPJrQnpkKdsnkxrxyugfMDm6mLVvD6nEhKn9bkACsxdozfT+aBjXB7oIZReukNPrRl5tpC8NifBZFIbmEZGoUZsXXH5yHf4j7Si+tfPaP1EZzbbOGBZWiYXxl3GyMhrkkXy5LgxPZM+C3mj/eSTBXj4yhwm/ocWLufquATD6SBF8rAISrQE+NVpXL5nTzUiEOqM7o9YJCDbgwgvp0Ib64vUx2WjW++D982PYv64QrNCgQadgc2B34CvTg1o2XVah/5p8SNW21W724Koy8RFyT0WfNpB8/f3kefSJMS+E3jiVgVqtEqsmHHK5zZx5G9h0Qgxo6tCeXw8/waYd2kGBKPr3NHYNnJ/ZyEv/6VdXTWTaBDFji9ioKNIIe/budUje+jgM7bQc9yZewNy4K3jgm3nM4JG4/LjgdvnI2wtGXlr15y1Zy4TEGTZO280Exx6nFn2CSN/mLvePtBAjtj/WQXCJL64l47Hv57TqhgtWjOMjsIcjmvAafWW49soYzNq3DGqDbWuXPX6dMx2HSuLt/j1z/1LUdGJhE4JSpsf+WZvZQ9YevUkKTZt+GxXOXQPHS4VXF65EyZMp0IUpcbMpCCb2ohcO+Sw4WsyVNAe6bGG7PboIvx+Tbe6nUYbfHr0DRoFtlTwzDEYF913yVKRi6HErF8RDnRAET+RGYzC+LY1ln0loj1X0a50/vzD8OIaGVtk9V5UYjKffLEFYX26F63XCS4aH4Ex/zFlo36jQU9wZcw2jI8pQ2BiCLDtTknqdklnsHFGUNgA6pWsqPo6HCq/FV0GSEYJhoZXwNBYmXMLEviUOj1l3MQ1X6sMcHvPe2bG4GR+FxhFh3BLXWyxsJLj1E/ribA1wtqYPWwQNDq7Bxbpwu+coZQbEBtR3KjBiQHPvKo2vKG1V3G125kk+fBmh2Y2oKuUjsdeOvKRZMMqtT/WX67B+6m6HSzUS3A8y9nfYH+SjhUIqzKoVINcJUsW9d25sB+ce6luYUg1nCVFomGl5/lPVWPB0tdPnczxIeG89OgQN4/tY7SPz7YRdDzk0JtCIO2PPvR32r528F7NiC+yeJ5f85GzzP2O/w2PJuZ328a1x3+KRIXlWFjVSlR1f8DfI2rQnhM/v2IWJfW/i7dwJWJE3ket/PQSP0AMtO7TArgskkXf3OvRpMVK8cGQ685PojGd+mMlG6bfGfdPl/s3edw9z5iHIpfLWk0O73CanlwhvZ4za8SgqHcSv2eOP58bi5RNTrCxsqdt+ZdPC1n4KdO7utWzUPjJ/PQYG1brUb46XCu8X03dgVERZ6/fJ0UVYP+Ufgs5NDqnG7ju/aP1Oli9XfBvIPbK9Kkxjx1G9LSqDHNP3/oLphRccvBtFTcEu/DrH44S39OEkaGIDOz3u9VOT8WDSWdzR/zr7nlvdF/935l8E/UZRUxD+s82I2d2Q62Vps9l5vkwV4NBHmNNzOP2/ookJYNqGzlgYfwmToooR0eLKSJoGW843r40+jPjAOqt9ZCrOq7ZeEDqCoozJ5dKWz4I7SEhR4/FXHeuQOR4mvDXT+sHoL0w1TCPW5oKhuFAb0foqLleZR7O2lKoCoDV2/jA8PCQPff1se5aRU+fN5kCXphZzYq9aTW86Y3hYBaYPK0bBoAEu/Bqnx4wUNRQyYyc/QnvWXhxp9f1qfRjb2vNR/ihB7Q0JrkaWzLaZlxZg7+aNhyvEBjQImgdbID0xPSwfX0pDPE679JsccejxpCNEYlAtSypCERf2cNcc+EOBD48FUpnRJpdrmIlcWdJ1P2OOm6cN+iAfRPiqRJtXknO5xRq3cnwWpvYzL+zcAVnHwl2wrDlCT+6fz6aK2ibHTcJb+F/p2LfgC8QENKCrkMUse95GKFrMvOQIbnTSB9gZRoSXY9uM7W5rn+PhMWwD31vl/t54GRRlnPjScR7D1luih12Fpg6UDfKPE7/q6a5wvIQuCS9F3L478WtROvLfP05iaUxfOzUZngBNYn6YvwGBPjwJSa8U3q9K4vGnc2NF6Qh5pVEsW70DjUNXIX/iHTO328zd0B464snsWVA5iK2j+LaiF4aL3EtOtwgvOcsUNoSgO3koKQ+zBth3n3QEmXkpekJowVqy8jkK/PT1MWDlsiMu9YXTdUSd80okJjw//IRVsruZMYXIiC4W7TfIctdZomlH/aNoD0qKIoTnU0+w0doe5LjTHVEhHJGEd0ZMod0EICQT5KdgycJIkG9DqEKYjnVISDXG9rnl8Jh9xYksAthZ/OR6zIu7grjAekHH07XQsY6mGGTWXn0u3em+cHrIwrYo/hJbxGSXxqKyJfNj25HoN0emW+37vEC44/aI8AoMDKzDCReEszMC5FosHZiP+7LmCzqeRPbFo3c4PIYMNqRD5njJyEvagNkDCph/bvtXcl+/pk69vywREbbYdi0Z79jwUSCHHCGLrM7m5/dnzWN5fWnranuEr0yHj4YL81Hm9LDwUpDkpmlf4pNLaSzJc/sgykNzNjm0k5EPw647tzndyYOzP0e4CFkiaf6alfkZ26i/XUXVKMN9Y7iJ2CssbLmL12HugaUsCw2HW9i8ysI2ZucjKOoFgnt+yRoWzs7xbgQL78BXT8CoMtl1+KbXMAUr2po2UDjQO11ILi1kOnNswadsTr1/9mamtXBExu4HUK9TuK0/HA/TNsga7Sf6iA2sZ2E4j3yXaVO4qbJlVolzpaecQWeS4qFvM2EwShGmUHeal8FVPTGnFxopajS++ODC6NaQn/ZUqf3cGoFLAZMXaiPZg/O7Y9NQ3BSMJ1JO4652ljgaof8yab9DTQP5LP9h4tfsDfL+bQeYftgWVFEz6u/2E2JzvER4G3UKu8mhyZTrqHSV2FBxQfKToOyQ7WPmyGeYopgtovvIkFxmcWuL1iDD2Rrzg0DH2jMPSzRGBJyzPpfjwcJLRajtFaiGg7kwZa4RG5qqTGsXfbEo4VKrOfdA8UD8WBXVwbeB3hCWqkIUXUEPVlKbOTIJ/qeXR2BxwkUWX0fCzOkFwkvV02UNzgni1msp2GOjmntXiQ+sZ34TbSELGuUjE8qqvPHMfD2j/3Wr8HuK9FiWmE+KRJvnSVV6KIsbu9B7To9MG2iuJ9E7l6iOzMliGBnakl06oENQJpl+bblU0lyXrGq2WJk7kc2BmbC2SQtF+dPs1X3zvdGE6PV8vut1whuz+jx8rzkXx0bFrt9IN9eFIHFwtlqQM1Db7Rdk5DNB6acsf7cUDbRAiftW5k4Q1D6NygoHnmac7qNbwoA+vpiGZ3+YyT6HKtU4s/hjt/3Wd3M3IjnEVp0JSUsdtrVsc9VIsWzQBazJ2AvPxyRS9bpeVkTwzc1Xsd1vNKuw7grkjdV2Fb/5jp347GoqdjlIc+pM2+Td1vai6JekLb9p0QF3linSwomFf8M9Xy9EQUOouS2JCQEX6xD913yPLiL47s7L2L0+ElnbvdPfWMg9dUl4654fjLpBYaKsxPfO2sIcdsg3ltr7qiQBvzs21ak2aE6bM38DJnz5oOhJ8WiEJg2EpfxV8NFyRO4ohFRj9Fjh/fBQPmIHa6DVSKDXSpGzPxirfuM+I5FXRQ/7byiC4kTXc9aSh9lrJydj7oElOFLen00pyLCw+raDLK3SvllbWjdb6fgpFSpVz6Q0pvdmzWcWNkeQGs3SnlCvsjqt0qpum0RvshJcT+PP+y5h9UsD8NTMZJz5IRBBYXpMyqzDyx8WIjhMj4+y8lu34PCOa4+EFBVWbr3Se9M9+VRrEHbwJtP51k/sK+icURHleHroKat9VEXomWEnWa6wYS310EioJkcVMStXW/0rfbeM9F/eGIwKlT+r+PNX0ttCgssOCrlYoFH57dzxrRoFKi5Irp1nqjteA4nrBxn7WCb25SOPINqvCXs2RuDkYfcFiDpL8ugm3Pe8tTP8oFQV7n+hDFq1FINTzRqegCAD0qc0YPn71xGf/NMgQN91GvMDf2hHKKrLfTBjSTU+X22tH+91ucqUt5oRcrgMg4JrMHaxCmva5Pz6bdpR9p1GrczYq0iLKGeCd60xBL9KPmPVjq34tiCFtoOze9vvNEIfKY9BTnkMU5l1xoCABvwy6az5iwlYkTuRjaYUYFmjtV0xiOZSxyr647nUk8iMu4KcrYFQfaWA8lbPaxpun1eL5NHN0GkkKC5QYsm/WgvwmNs7aoMCgg1In2q9nwTaAo3Kpw8H4nR2EE5955kFIdvTpQmisrgJQwuuY0nCRav9DyflsRGUEktTtC8J7LR+NxyWaHWG9MhSZEQVwV+mZ7kjyDjhCFqkBcq1CFVo8FjymdYYu22FyQ59kynS2EdqQPbuEOxYG4mrZ50vLSA2E2bWYeFjFUxgx8+oh7pZnDn+sHFNTOh9/Y2YfX8V7rrXfmXQXpMlsr5GhvzT1v+pNGJRKv7HU04jvU8p2zc0rJJtYjEyopxtBP0WWfLscb0xhNWmIP0sjcLO1EZ+e9sIRG3wg0+tZyQfWfpUBVLHmw0uNEWgTSxSxjSzjdBqpNj/uW1Hq14jvPmnApD3bATkT2tY5kTi1ZOTmU5VKbC2WnehM0ix/NgUwYWziX5rL0Km6vnriBqghURqgkLpuYtFr8zP61OpRuzbubj++zHstbN/1ma7roTuQNJSwYdQ6eV2R1bSNvxz1laM3v6ooCryUq3BA/T8JnZP13ybD6Vf9wmuhKyR/uaHVq2SwhOLz7mk57WHVGrCniJakEmYMr8nGL/rIeY/3GVMJgx68ag93xwr3Knn/ememgXKjZlg7bIsLRW1lfJu/fEeyxI5cvujKG7qmRUrhSINbVG7uQqNuEIFt7tYNGQEyop7JnRp0+nzSBwmbnJuMRBVeI1GYHHKCKjoNdNDzNjzC4fFuztDXqNBwuunPEZwW+9pU8/d00czUlCYL04Rco+dNljQ9vFFXFA9qn+ZiH+bc95hXWGxocR/tCB741QGssuEV+wJPF2F8L1FkBhM8Klyzmmnu8zD/eI1kMlNeGR5KTIyu68q581rShgNEvzllZhu0wELuaduKaiiqFCjtEIB9Sc1WKMajM2jh2J0ZBmeSz0Bd5MQVIfXT05Gfp1wNU9wTjlCv7sFRbnnvRrbcuu6WZuz4Z0o7N0YjqHpzXjgRbMq0p3EDNTgzy8NQMF5zxp93fouIqft8h1q+ObVYkRYBboLStbnKK1UW4JzyhByuBSKUnGd5d1J4UU/GAwSJI3svkpEwyc0Ibxv92mQhOD2iZT/5XqEfF+Khv1N+GZn97jnCckGGXykHCHZpaxvypveWY6qrEjRbfd06sIaNm352dVh+/H7ILZFx2laPZmah4TgtqiboiS8s0VKaBWadD4oU/t3cNrxu1SHyJ3Wbo3exo827ikxalIjpDL33FPSOKiaGlBVJsf1i369c8HWGeQHfmP5KOy5awviB6rYIsQdUD6JLQUpLE5NYjRB3rIQi3vztKjaBE/y5/3g63zEJZkXdu6gvlqOfZvCse5/+8MrndHFhCxHEdE/RSTL5SaXLUmUP8JyMVKtEavzxmBdSxlZea0GcSty4Q48SXjFvqfNDTIrI+PGd6Ow7UNhbrBeqW1whsenWDvUTJ5bi1c+sg5pF0r6zodbIymiP7mEwNxqJOI4fm48LtY9NQFLUofDoPc807BTIy+H42l4TBFBDsdZuPByvBYuvByvhQsvx2vhwsvxWrjwcrwWLrwcr4ULL8dr4cLLgbfy/6mWQi63VeobAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAABhCAYAAABoHBtnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMqVJREFUeJztXQd0VNUW3TPpvQcSSEJJQgKB0Htv0ruKBUHF8r9il2/vXWxfv4qCChZERUGQJh2kd0JIgCRAAklI7z3z1z6TN5lJJiEhkwJkr/WW8vLemztnzrv3nH3KVWk0Gg2a0YwbDOrGHkAzmtEYaFb8ZtyQaFb8ZtyQaFb8ZtyQaFb8ZtyQaFb8ZtyQaFb8ZtyQaFb8ZtyQMK/phaPUN6MxkDzJFyEzS7Fk6JorXvvyoUH44WwnuFvnYt/kpbrzv/zPE4vf9EZj4O/SXxvlc5tRPVQ1jdw2hOIPGJeO2fMTDM6VOFjAyhFoZZdlcP7P8wFYc6E9vhq0XncuKc8WGYVWMFNr0NYhXXc+M9Uc+6M88OS+EVg1agVUKg2+e8cLu9c7NWnFbyyZEza2pfBsXQh9bP3DBdtWOePV72J051ITLZCVYQYzMw1aty8wkPnRf+zx3jxffLb+NFRqNCmZ13jGr0/MeSYea1MCoOmghl/guQp/zUdUpgvePtoPz3bdozvbwSkFar/yd/azkz3Q2/MSenvEG9y95HRneNlmo0fnBDzjehh+7fLxycme8J2ciu6D45CdYYbv3vXCjYY5z8Rj119OsHcsgV9gfqW/x56xxteveeO+ly7pzrUJzsMwVbnMf/yoBbr0y0HnvtkG965c7AFP70J06ZeNf79xEX4d8vH9By0RGJqL7oOzmoTMG0XxffzzDWYHx5E2KIx3R57eLK3gTIYr9id5ISnf1uB8B+dUORSsvuAPZ6v8Soq/6ZIfQlySMbp1DG5tdwqbL/khNtsBvfteQv8WychINUfkUe2zw/bZISu9ScwF9S7zlj6FsLIuNXrt+UhrnNhrj5REC4PzbYPy5VCwbaULHF1KKin+3g2O8O+Sh/5jMzDmtlTs3eiEhPOWGHVLGroNymoSMm/wT3RwLsbY21Mw/cEk3bmJG2fgcp4tOrte1p7QAMkFNnC2LMD6uLY4neGKT/v/bfR5NNRSCmzgaFmIklI1kvVeEFerPDhZFsLOvEj+XVSqxouHBuPXEX+gdZnp5ORajFe+1S7dj94WhJjj5rDQFCP7OnoBjMn836MDRbEDu+ZpT2iAtGRzODiXYOdfzqL8zy+suPqWXaoB0pPNYedUgpISFdKSyl8QZ7ci2DuXwMauRP5dXKzCf59pjY//PIMWPoWVZP7E5ABEnVTB3FLToDJvYBtfgw9XnkWn3jnVXlWiUaHzirn4ZfhKhLiW/1jGQGUOWTEXf43+Fd+fDRHnVsHhqd/CybJ8lrsSbtk8BYNaxmJYdgSenOpP8eDat/Grkbmm7L8qoLREhUn+nfHRqrMI6Jxbfo2q7Do9URQXqTCpfRd8sSkSf37rjjVL3HR/W3EqDPZOJZU/R3mO8swyPDHZH92HZKPrgKwGlXnDKb5Kgx8OhMPVsxhm5pU/8j/7h8LWvBgvd98l/84stMJ9u8bIbE84WhRi+4QfMWLtbXip2z8Y4nVBznP0WUVWsLMoRGGJGQpLzXTP5D10ZBUUlJih/5+zsHLU71gU2QUFJeZ4p/c23d9ziixgrtbAXFOC1MsWuLNncJ1/iEZV/CvI/IPHfWFtW4KH3rwoSpmdaYaXZreV2Z6wcyzB0r2ncM+gYPzrtYvoNTxTe2PZtbb2pSgqVMmhgPeo9ERWmK/G7T064rN1p/Hbl54ozFfhiQ9jdX/PyzaTsfFoSJnXO4+f5++I/Mfa4O2fo/HM6ZGYs2s8Vp4LRGS6K+7fOVYUl8gttkBecflS52hZgOdC92Bgizj42mXivd5b5fw7vbahs94qUKpR45E9I5GQaw8b82KZ4ZVDUfq/LvjjpUODoIEKmUVWKIUKs/xP4u4Oxw3G+mFYb6yLbSc/gqtnEd5ZHo13lkeJk3atwcmtGG8vi8Yn833w/O3tsOk3F8ScshbF1pTJPD9XjYK8MhVQQWbq+1++hO6Ds9HStxBPfRwr5x9fECuOqQKaN2/9yw9J8RawsimV+5RDUfrtq5zx6bOt5f/pzJaWqjBxTjKm3W+4gn/3XkvsWOPU4DKvV6OKM0ReL3Ns9vHHAff26FCYJqudh02uKODey966NXBkq3OIyXLGVxFd5cw9gccR6nYZ09pE4nK+Hfp4atmFXhWcV85qnVySYWVWjF0JrZFTbIFBLePE5JkdcAKbLrZFVJYz2jumw1xVivuCjsLRogAu9pWZjBOpHnC2zEd8rj3Wx7XDnIHH8VNUJwROzIWldSYObnVEUwdlTiWic3r2hA3aBudBo1HBrUUxcjLNcHy3ve7afjdlIC7KSuIcVFgqZVC3XIy6JRUpCRY65avovPJa/5A8WFqV4vB2B+TmqNFzaJaYPVPmJmPPekfEnrUWh1ptpsHN/7osL4WjS3Gl8Z45Zit+RdIlC/Etps1Nwuql7gjpkw1L69J6k7nJZ3zOsgFdcqHxs8aAmdmYcmuicPDvH++Dhzoews1tIxDgmCYOZ5BzCsLS3FFUaobJfmcQ4pKEtbHtZdalnU8M874gbIyCU+luYgYpMFNp8HSXfXC3zsPJNA8cSm4pJg+fw+fuS/KS2Z8vgVqlwbjW0YjLcUBagXY5Nwb+jWMIS/PAhri2sB9kA7+JahR42aApQpG5hWUpBk9Mx6S7k+HZqhCL3/LC7Y8l4qaZqfANzIeNXSnadczHmeO2KC5UYfi0NAR0ycOO1c7YucYZpWUkT+8RmRh7R4ru+dEnbcS0UUBlvue5eLh4FOPMCRuEH7BDYYFankP7//hee9g7F2PKvckwMwMGT8xAwgVL4farAv+2a40zTh+3xT9rneDuVYQOXXPrT2amtvE5CyyPDMfUzdPxYPARTG1zWsyQkWtnYsfEHzFv9ygxX/7V8bDY1H1WzcamccvQ0rZ6h5ejpE0+at1MvNZjh8zqfDmszCo4UnrILzGHpbpEFJ7g/T1XzkapRoU3eu6QsXE2pO3PFWPW9okY4Hmx0tjePNpfXgDbtFz4vHtc7NSa2qENYeNT5r+EheGRcYG4dV4iRs5IQ/IlC7HNv98fjjceaIMeg7Mw85FEsalvDe2Eb3adEuW6ksxpo987OAiPvB2HHkOzxMzh51UFXm9uoZGXQ/n3zSGdxNR59L1YGZvyXM7oz9zSHt0GZVca28JXWmHXWid5lvY5ppW5yRW/1EKFc+/2wt/jl8PPPlNrZ2uAEqjQ/Y+7sWjQOvR0T9DZ31RCNS+4wndiRLbnyjnYPfF7SUn48WwnMUPWjvmlynt6/DFHaND+LS6Wj69sJRExqjRi1gxZcweOTP1GfATlvP7Y5u0ZBVvzIrzdaztKi4EpgZ1RVKBuQs6tRiKji3dEwLstfRutA0plm94xBK8vjRZWR3deo9JOBleQeVa6GW4OCcFPh8Ph4lGENUvcsWapGxZuiaxqGJjRKQTPLzwvfL1yTidzlUbGkHTJEnf1CcbvESdgbcNxaCqN7c0H24jj/fgHcSgtMb3MTWrqtAnKw9fbIgG1Sr4Iv+iWS364ZcsU+SDOrir+SHpMS01+AMLBohCbxy2Dq3WePHtymzNYPHit7u9zto/HqvMBBvesGr0C3d0TDc7x83goY3t49yiZ1an0yvmKYyPT9J8u++QlGbnhNkTN747Clk3D7NHJnIql1trf+/52xBNTAqBSa8R80f4WZTeoALW6ZjK3cyjFt/9EwNmtWO4fPj0Nb/wQrfv7c7e1w+YVLuU3qID/bTiNjj31Vu+yz+OhjO2N+/3wza4IUXqO0djY/v1GHOa+EI+kixa4d1CQAXNkCphM8XuNyMQ9z8bDxy8f7/beikURoTiQ5CVsTXi6O+bvH4qCMqpxY1xbPL1vmMFxLMVT9yy+9c8dGCK2uG6gKg187TPFpldeBL5Ez+wfKiYPlXLpmRB8d7qz7h46yozSVoVAp1TMaBuJz8J7SDxAHzSL5u8bJisN/Qe+cLwmNscRha7WSJngi5xgZzQmFJm3al+AJz+KxW9feEgkNC9XjbNhNljwmK9ulvxnnRMWPOprcEQeKQ/2aUpV+OgpHyTGWurO0Vzx8ivQmS12DlrW5sMnfIT358xNh/aPRR5lDwF++dxT7PmqwPSF0bemSrpDUZGhMtP84Zi50tB/IDPFAFjCBSugbNVoUoqfG+AI7+FqdBhcKJHWqX5nsCuxNc5nO8LbNgsjvc+Jo6mAisp/6x+kGC9kO8osTPAcVwgl+Wx9bDsjn8znqHVOsI9dFoo1aoM0BiazrT7vjx3xPkbuhjA9RSVlypHQWq79J1FLw/HZyhjK79FgvE8UzLvZwmckENrfMHmuIdGmQz469syVnJuRM1JxeIcDLp2zgmerImFs6GgqoKJS0fSP0lIV4s9bYe/fjsK28XrF8CWnvuuvyi82/648t/fITKE9S/TImm0rnbHlDxdJaDu4rfKko1YD5uYa7TM0kDHz2iM7tNfS6a6k5CqNOO10mJsMnVnsZInUsT6I7wyEpeXjwxO9hYZ0s8oTdqWlTY4kl3la5yJ8vRsszUrEuQ11vSyzBxPIFCblt5ggLIsKxnDv83i/zxZR+OwiS5zLdsLHJ3uii+tlcYLTC6xhpi5FS9tsfNB3i9z/TGh5ApsCL5scLD4dCgt1idCgdIjj8+xkLObqUkSku+Hn6GCsGPmHXM/kNbJCvPbn4avwUb/NurExxpBaYINWdtlY0GcLbt48BT0n5KJLjywc2131qlKfyM1W4/RxG0n4Ig3p7F6MwgKVOK1MLnNrUYSoMBtYWGokOaxDt1wx5Tzo1KogOTMbl7ti7fdu6DvqFJ7+5IIofG6WGS7FWGLpghYI7JoL95ZFMgtz5vfwLsL8T7XBw/teLE9gU8DPXrHQAxYWGoT0zUGPIVmyMnAspFmjw22w9kc3fLLmjFz/wwctcfKAHUJ6Z+ODlWfxzOfn5TzHxhhDRoo5WrQuxPz/XsBjk/xx1kRpDXWY8bVOSex/uqCgrb0o7IITffDXmF8x/K/b8EGfLTiW2gKD19yBGZumisA3jl2OLq5J+OZ0Fzk/Zv0tuhn15cOD8O6xPgZRv7k7x8pzqYjLh6+Se6iEzx4cgo/Cel1xhH/d9Ct6usfj9vbh+HrgejG1hq65HRdzHORz+YIpSk+I/1EWV+ff9cfGz356/zCJHluotazGF+Hd8OS+4SKHhoFW5srx1/dukuq7cHMk5vQPFuWIPGKHWb2D8djEAJHloh0RorwrvvKQ8/cPDdJlDvzvuVZY9IaXgcxfuqst1v7ghpA+Ofjgj7O4q3cwMtPM8OGTPlj6fsvqh6cCvtwciZDeORh/VwpeWxItptbsvsFiQnG16DMqQ6f02nuU76NdTWTF0WjHxvHSJFu67xTMLUu149T7/nXBVbM6zu5F+G7PKWgszXSOEhkQ0oJ5JRaYvmkq7g48gQm+Z0WZ6Dwq0Jo32neObAlBSrFEoza4Nr/YXGZ2KhqVMK/EHDZmxSgs5XWQ1aM6DPhzFt7qtV1m9q3xvlg2bJVubPQfxrSOxvt9tBFh+bwSc/EvjqZ44oFdY+TcpnE/S1BLGRs/kzTnVwPXSxwCpRrkJKtwZ8+ORuk2U7I6iswrmg6kBRmFfXRCAKbdl4whk9NESaxty2lHmhA0b/TPFxaoxUzhMxiBJTjLcmYmjUjN4HN5PRWYjihXjyqhgaQnPL4gDtHh1ti/2RELfj+rGxuVf9D4DDz1iXbFkM/LVwtrE3HYDq/c3UbOLd4VIVmfytj4mbd26YRXl8RIQE6JBtdF5le/bqggARHAkNOleXP39vE4n+0EtapUp9j6oOnBQx9aPt7wnLXey8IVQ3nWx2G9xOG8t8Oxaof4+YANaOeQjiCnFLS2y8Sd2ybh+6GrsaDPVnnRXKwMo7fWZtrPU140Vn09e2AI5nY4pqNE6Z/QYX/x0CDdeGxUxfho1Va8eFdbZGfUYzBcJ3NDkPF4/o52Yt/THDF2DbMfeejDknx8eSxQoLwA8nF6n7d0QUuhNKc/UE3SoAp4afE5+LQvEAWl/T//Zn+8+0sUnv7vBRTlq+HoaminK6nRDL5R5m//HIWPn/LBjAeT0HVgls4/ocPOLE8WyCjjZELd1crc5L8SndTDKS103G19ICrT2SCvpyrQ1yAcLAuFETpSxhx1cqk+41Nhkbq7JSIyw81olJeriAJGhjsOz9EFWxoaZGTCD9rJf+sLsWesZOa+EuhrKMlqXn6FiDhkKytBQOey9OdqQCqTVChzijJSy8kQBTHh5RSyvVOxXHu1Mr8qxXdwKYZ/aL7QlUQHp1TJkaH5oE8LnstyFiVlnowp4e+UBnerKwtSH0yR6OaWiIPJLRHqmoRLufa0UoyOjVRpd3eW42nECXetsDJUhXw/B5TkFsMs13Tsg4HMQ/KEriTaBOUjL0ct5kNRoVqX8hsXbaXLkzElfAPzhWKsDZiTH9wjR5xXph9cvmQhL6exsdk6lOr4fzrhzNmvT1yVjU+q7OEvEtFn1V2y3DM6Gpnuhk/De1SaiWnjf9JvUyVzSHlB7CyqD5tXB64q/DwpNKnBZEdunmNePfo3fB0ZKowRUxeMmWP6oO1fUqq1j+nDsFaAK0JxqUrG4GmTi10Tf8Cwv25H6ScXYR2WYXIbnzJ/9L04zAztCGu7Ujz/5XmZGX/8qGV5hmUZaOM/94WWHVGgTR9Wi8loY8QUqilIgRbkqrWFJjWQObn5maGd8PnGSPz6hSdys83wyLuxVxwD7yOHz1XA0kojtQK092n3cwxkiZhyPbt/MC7HWYo51KCRW/7g30R2QXqhlTiPNcHnp7oj9Pd70X/1rEo8eW3AWtweK+824O6rA5X2yNRv4WOfiVe77xRW56Z1t17xPgayOF5Wiin4edgqzAkIQ1/PS9g54Uc5t2XcT7o6gfoEf/Dfv/KQkj06jzXBsv+2wNTAENzWrZOOq79ak2dGp06ilDUBHe8VESfE3n/47Tj0GZmB+4YEXfG+9x/zkfH+a1QH3TmyTEx8Cx2Qje8PhMuL993uU+it1AnUt6mzM6E1DmzviX8m/iBmgSLHIOdUOWfMYaSCj153q/DudBaDnVMkYktM/XsaHu50CCO8DWepK4GdFLaN/xFmqprPYJzxWGnFbM0R3ufQ26MyF80o8lP7hmPj2J9lluf3G+97Fi903Q0zaETBn94/XK6j+ZRVZIGxG24R78468RzMYfqg1qHtDnh2Zjv8cDAcdo6lOtOmXXAefjh40uBaK+a/lAWb5g4OEt59xgNJaNcxT+hBYt7YQNzxRAL6jqqd0rRqV4Ale08ZLWypCpQhSwwn35uEfjdlSoF6RTCK/N4jvkK/avN2VBgyKR0PvnZJZn0q+Ptl0ebgHrkSa7h/mPalqC7r02Smzk23paDrpAKU+ttKDj2x77K32PukG5kibAz8lI0X26GXxyXsvdxK7unfIg43tYrB5ng/dHRO0QWzjDmS357ujHf1qqWqQ2ahJV44OESqq4yZMdsu+WJfkjda2ORgTuAJGdv8/cPxr+DDaOeYLoEq5vZvutgGr/XYiegsJ6nMYgCNpg1fCsYWmNfPet+jKS3kJSJWP22DmJ3mJjV1KHMGgrjk0+Qhju+xx4m9dmLmMEXYKDTArnVO6Nw3B8d22ePYHntJHhs4NgN7Nzmifcd8eLQybCGi70j+vsgdT+pVS1UH5vp//LQPnvzoggGNqoDUJsfs1rIIU+cmicyZnjBzXiJ8/AskUMWXe88GR8x756LUCfDlom9A0+b9R3wlR595/az3Jf3Zd7RWFr9+7imp1vVq6tA7D+qZZ2DL0waOyHDThfqrQm6xlicnXUglv6l1jCxXecUWKNZzirk6/B7TQcemcEZnWWJFMI9mRUyHSgwSZwwqvBKMqoih3hdEuY+ktNCdszEv0qUvs0j9ptbR2meQ3XFPlJXt1+gg/BbTQVaxwS1j4WOfJTEJsjrjfaOE688KcEZ+m/JiD1OAMg/unmvAqpD/jjllIyH/6pCfYyY8OalM5ugPHJchMuezSvTYYyri37+46mZPoUWNKDD5c0Z7qYwGEOqz6rgKc/yp3KfI8pSBL4i6jLxhXg7HZmPPQJWW3SEztGGZq3weTaaew7LEZGK6AwvouSLQtmeqdIOYOjHZTlhypjMm+mntS9av7k5sbVASWBkqLI4MlSKUUa1iMKpV+V++P9sJ9sGFYnsTVL+vIkOl0Jxce4BTmq4WVx98MRZGdJUiFkVpCSqpfi2tMbhZ5aKg1Fz3onBm13+R2fVBeQZTJ/5JaIWvIrtKMlzY9EUSd+C4Dye3lLLIc1lOEpHO7GcJi/w04JxpS+cuxlhh5WJ3DJuaJv9e8YUHjuxykAKUqkCJMH2AiWH9x5Q73ASTy2ztL4siEWRb6HwGhOYK18572BOnIqi8rNgaMT3NYNpkApt+La0xMADHoJki83lvxxk4s+z68MQCbbkjUyf4UnM2Z23BqrMnRPk5blK3T318QWRCXyc/Ry0vDsdWL4qvpJD297yIviMuSjBHyZbkWyp59VXdq9JgzU3GlyCmI+iDSry+mjx7ZYZv45AhaRCVUJb/r4zNGOaH7jO4Vj5XUqaBsFQPSZegI8xxv3G0v8z+3w9Zg5vW36obA1cmKj6LY4i9k5bKi/pnoju+gN6bXQcoMmcw56P+2TLDSequIvNq1mzex04IxvDhSkOnmDP8V1sjqnwWZ3hVmY1PO7wSyvL/q0t5vvf5eINr9b8fc45euqsdVpw6Ibd/+bK3MD/vLo/CfUO1tjzv4coUfsAWcwdpHeRlR0/C0bUEq791w+cvVm9xXLWNT0qqTXA+tif64uHdo3U/9kO7R4mz+lTn/VdMIzAFHvpntJhKL3TbbfTvyfk2GLzmThkbi9arA6vDhq+9Tf7/h6Grhb+nUpNuVaq7+P/8MfgiMV3CSl2CGZun4niqB/p4xmPRIG1dAKu9KJcDy63h8tsFk9j4iswPbHHAG/drQ/o/Hz2JN+5rg3ad8nD3s/HVpxGYCK/PbQOPVkV48NXKqwCRlmSOWb07ytgqtRepANbX3j2A3RSA936NErOGSk0TRqnuUjJAaeczXYLnH5sUII2oWAv8+lJtXx4Lq1KRxZ6NTigpY5pMXoH11bYIrC0JlmX9roAwOR/klCqBK6YX0FmsiJ0JPnjveB9RnOXDV+rycE6mueO1wwPx8/CVBklS+nh8zwgM8orFtDanDc4zfVnxE+gbMFPyv/026UwlnovMcJWxMdenKnBszNlXMjvbOmRckdPnS8HPezDoKLztsmBvXgQ/B60ZMWvbREz2O40Q80QkHYMoal0VnzLfs8EJF2MsMfnuZO04O+Yj8YKlhO3pLFYE04G/eUubfMaZXUlDYPH55y+0kizIqmT+zkN+UmI46ubyLnUE05fNLUolO5MKxiS45748J9FZgucYV+DY2EezKnBsNF+UzE6uIFfi9PlSPD7JH7c+dFn6ebKtCSvNiP/c0l7MLjJWHGNNZV4r5/briK6iVCwpZJ47D86G/OHZIYH9LZVDcUzpgMZlO2CS3xl8EtZLV1zCtOVxvlHVft4Qr1j4G4msMv1AYYBoFk30PQt7C+0PwD48n4d3l84L1Sk90co2S3LrOzonS3F5ql5qAoNs/B5kiAhSl1+e6iYv8ATfKBxN9URWkaVO6QkmvbGFYY6NNTaUXJmrrgmoJAzaePsVYsvvLnIw4Yw/PJmPr1711h2KY0oHlMUbw6amS0alUhjCtOXBk9KrjTv1GpYJv4DKkVUWpFDplUov+hpCqzJCH2mNnz5pAf/OedUqPdGidZE4pe1D8qTAXd8u58z+1WvewhARpC6Xf+opJMXQyemIOGKLnCwzndITTHpjJimd/X2bat6RocaK32NIJhJKHWT5p/nAGZWH0g2BSqOc47E7sRUS8+zgYZ0rRSL3Bh4Tp5gMDsG8enLpVc08xJQ2p4VCrPYLqDS4p8NxXcJZdpEFzmbplcNVA1KXM9uHy/+fyXQVmpWriTKz83swOEY69WCyl7zctKvvDjwudOeJ1PKqMeIO/5PyUoanuWPFuUDUFZR5aqK5mDI0H85FWMuhdEOg0ijneBzZZY/kBAu4ehSjz8hMTH/gsjiASmSXufIMAKEamY+YkSZpzNWBdjxbkSjtQsipM7BVEzBdYdyd2g4O509b49hue8Sf097L73XulLWYOczbD9tvh7hoa3nRpt6XJHTn6WOGPVQnzE6Gd5sCqTsgK1VT1NjUKU0IQFahpXQcSCu0xsKB5e25FbB3ZXaxhdB7kzdOx70djstMrw+mCbAIRAlsNSXcs2Mc+nlekt47CtjK5NXDA+FkmS8+BVcAfj9mepLyVEw+ZXWjqfTHuQ748O9QtP4kDL+nluf71xaUOWe/ha94IzPNXNdvUh80MViQ4uBUgofGBkqgSmF+FFAxzSw0VTaJbUy8cGc7hPbPxs3/Lp/guGL974VW8p0efPWSyIDVV/+5uT0GjMvA5HuSDa4lLfr3r65Y/IY2d6wmMq+V4jO8fzbTRQJXxhSfDZlu3TIZYdMXG9CLxvpTzut0CNcCBqyehedCdwtPT9+GDI5CZ1ZE71Wz8XbP7RhRFtgj1C0NX/zagDK/b2gQLpy2koinMcXnDPjkFH+h+5Ta2IpQ+lPe+UTlPvhNEXf06Cgd3WgSccUig6PQmRXBPH3m/yvBrJrKvNYBrPld9krpXUWw0PudY/2wa+KPVSo98fWgdZhboXVfTcCZt/fK2RJ4qium/T1N6nFriucODsHrRwboTKCBq+/UpSUzAs1x8Vg27E95qRnoUs7VGRotDciywIpY9Y07vn7dW9IYFIrTGF5bGoMZD1ZvMhoDZ9NbOneqFT9eFdjzh23FawpGgb94qZXOBLqzV0cxfwhGgG/pHCLHghVR6DE0E+uXuerO1QS1UnwGeejYMUAkTV13jpWiDNbZsj33YyEHJOpZHWgmMEpaW/AeBpTszY2H2GsDplWwt48xsEXJe8f6Gpy7o304ZrSNkCxMvrhMnaBjTNC5Z8CLY/s4rKd0euvX4iIeCTko6Qx1BYM8nPkYxaQisjSQ6ciss2V77tlPx0vwpjq7nf6BsTSCK4H3MGXB1qHuFPU9z1+qsks2HfbFbxhu1TThrmTpAMcszNeWxODJDy9I7S1BH6AgXyXnlrzfElEnbdBtYDZmPZlQ45e0xorPGb2Dc4qwMvx/9qZkRwT+8HRg6YRW6mtZQ7DInGZEdSB9yWxKU8QJqJhV5QU5WRRIb099pBRYC0vFNGR+fx5KV2Zv22zc6X9Sxsb8H04A7L0/ulWMgf1/NeCM3jY4X3Lu+f+rv3MX5oJ2PRusMo+FjMbVYMPPrrgYXb1DyiKPPqMyTRIn6DogGx7ehVW+mK4tDCfD9GQLUWJ+14RYSzmU3jpklybNSZaxMV8pPclCeu8PGEv7/8pFRvLdajrwZVEdMdTrgvSkXHk+QH5w9qVhUGeW3g9MU4B+AKOqDOjUBJxlPa1z5J7GBtMk9ItTWLq4Ia6dNLmlglMOBKPXbtZ5wgzND90r59o7pImDq7Q2v62MMbpasOi79/AsbF/tLI2bOOOxAIXRWvbHVKAp1TIk5MRrqqRbfneR2ZT3NDYCu+QaFKdw5xa2D8zOVGPibK0cCM7qpGR5rRIFZoIbO0CQ1SIUxsikzi1BhiMxzxafD9go/+aMb67XgYzFHt3+uBvrxywXaq8pgy8pD7JMyvdgMQ27OC8Zot1lkX13HtkzSl54P/sMbBm/THd/SVnaApPolJqAebtHy0qoPPf0vKevfnxlMmfQid2LX1x0TrfUky8nzafkuUwLDpGOauTbmzJKWbzDpDkLje57/PhxSxz7x17qbZVo7VsPtpEmtKQqv91dXmDPlA1qLO9TagIYtOJKSF+APXvWFawwvXP7Qrd/8KleRRU3Wtgj7b7Liz2OT1sMH7umrfQEg1ZsZkvlJSPDWuGHOx7Co50Oyi4rPBiLqAofHO+N+3aNldVAuX562wg833U3/B3ThP0xBUjpPbfwfHkng+6dhP9WwHD+ytMs9mjaSk/sXOMkLQGpvGRkTh2yw+2PJmLWUwmyywoPvuRV4dt3WkqPf+60qFzPzmwPvHwJvgEFwv7UBLVy17mRw0S/M1Lv+srhgXJu8eB1kp15Kt1duh4w4jn57+nS15LmUFPGYK9YifBytfptxB8yXjJS9Fd+HbFS2B96jVRkvgxKPx39wnrOYIwacysiUrnqssDbMO/zMuPXFfyRh09Nl8zG/z3fWpzY17+PxoovPSRow32tWFL40JgAvPFDjKQeN2X0HJYltcOcqz9efVbGSxqW/gr3yZo3LkBeigdeuYg7n0yQxlSVVwyV9PVkAh63D6LpN2JGqnR2q2nxea1MHVKA3IWQTp63Xbau/I+OYi/3eHRzT5QgFruTMXDFQg6mOHDHQTI/VCA6pzQFYrKcJMDVVEHT55foYGklXlX+DjMzWbyekm8j3eK4anR2SRLnlg4/q8rqyuOTAmRKANMW2BqQuHDWCp7eRdK4KbhnjjiA6350k8DVno2OKClSyY6DS97zkpmQiVxs1spC9GrbgzQyaPqs+8lN2iFWlb/DlGRGdDOSzaVbHFcN9vinc0ufhfsBmJTHpxIP9zovbfvsLYrE0eNBR5ezJpWeFOf2BB/pXKZQnnT2aAvTZOAMSbD3vCn4+PoEZ3emIChKfynHoVKhDTM5mefza0x5Xs62eF9sj/cxCZXJ5DTOYmRD2IWAW+lMnJ2MLStcJC+GSk+K8+BWB4y/K7mM8jSXWlzOjMnxFuVbLWWbmYSPr09wtub3U5SeReRHdhoW2jCTkysGeXslC/7AFkeRAXdtrPFn1fRCdhbbMGa5KDXNGc5yZDWYbEb2hnw+My5pAg0d/5Oo+OzAcnvrS71ILwtYJqI8H5wvgZ15YbWbPNQ3+H2Yg1TRnFFwKLmFFN8MaFFePEFYqktFBgr4DMY6nqqiBLM2eOXutpKdOX5WiiRwpaeYw9lV20WYSpJf1hX5s+dbY8mIU2KyTbm3fEbXj/RyNRg2tfzZGSnmUu1U3SYP9QpuGZpiLlRmVeYJ25Kw+EbXa78MvJ7sjgI7x2IMmZwunaNrilo5t8rwdiT4YNyGm3Ut9sjfk9d/93hf7JhQfeTWGCZunC4rSmOBzi1bg+i3Kq8Ivqy/6fXZVMDd1P8e97P8P1/2Bb23lit9nelvjUE67wPDO8iHfLMzQvalYjXSote9ZdeT6iK3xvDv0YFS32r0IxugLxY/Yna/YINW5QZ/LHtZDfpslo2tS99s2QRDCdrN/29sudJrTKz43DN2/v5h+CXaMN2Wu4kwbF8XsNqKfkBF3L51ksyyjYkx62+Vfv7GxkbalgdlQGwauwyDy9qLxJ6xlt1I6gLuGcuC7PU/lXdt4w97V9+OEravC77aGikBn4p4eoa/BMsaE/cPC5J+/sbGRpnyuKtvsMiCG0z0HJZZa5nXyrk9ktwCXrY54qCyQxpneio9I7o5RZZS+cRKLFJ8rEM1VphSG3AGZo9Mbh5Xr9AAe5O8pdMDV54/zgfAxqwECweuw6FkL7RxSJdxVBxbdrGlmHfM0+fEoODvi23w7dYgpMxPqFMhCmVOus/dq1A6LFw4Yy0zPZWeEd3cLLV0HGAlFsv2WIdqrDClNog4Yisd05T0gHqDBtL1oX2nPPFlNv/mAkubUrz6XQxO7reTwFrFzm0cG/fJOnPcBss/88SK8DDdrL97vZOcY/cFkzaNZYFxZl8P9GtXIs6stUuxVC8RZDFalR1kcdibsqZR25r0vqx3qCCNoQhPmxyEuCTrxt+zLA2DSWnsojyz/Skdm9XeMU1SEyp2j2M5I/t0+qJu2ZCUOdF9cKk4swE2ubpzVEwyGTzIhvh3zoWFVd1tlKCy3pf1DhU31dAyg0xX8O+SJ41jCSUNg10k2JVBicZyRvcNyJeVioUn+vlJdOSp9DVFjRV/8ZveuPBMKJ53OiiKr2ypSfTxuCSKklFkJYGb+SZw7BoLA1vGyaEPFqdwZSNjxZeio0sylpwJESeWufuPhhyU65igxhefnZjZTaKu4STKnLCxixPFV7bUJKg0VHSyOlQGXSH3NYgeQ7Lk0AfLCBnNpW9DupJMDh3doVPSZd9cJqQpW5EygkvZ+AXmS+qGyZ1bKjfD+oSzVT5WjlohB82b3891kH2rrkd8EtZT8o9e6b4Lt22dJBw/zT1KghOA9JEvNsfsbROk3uBStj0+6KHdTaWuIAevdC1jxdNn60/LQfNm0y8usm/V9YilC1rgwhkraXHy1LT20ttfVjSNtg+obP+ap8YzM9tJPe7lOAtpRV5T1KrYfOHWSHmr9HcGJPiDcxZkum9tGZ1rAUp/T9Z+MhbB78hcHBbR0wRiU1xuRcpzLNDJ2ZiNL15oJffVtdh84ZYI6XFTsUTz2ZntpW713ufipUXH9QZNGcvK7y1bgKo10vtn0ZteiAm3xrNfnJetSHndK9+ek84Nn9dC5rWa8Z+/vS22/O4sm6Rpw/lacL+qB4KOXldKz7gEKU42k9Luz1reL4aVaCPW3gZnywJx4pWtSLeO/0l4fmn9aKL9AbjhAzMp2VzpkfHl25myMOWWhy5fV0qfn6PGnH7B0kxKti6ldpbtfzt3SBDm9A+SVe+pj2N1W5F+tydCx/PXRua1UvzkeEup32zrmG6wG8nK84H4J9E0DZQaCkxHYNPaN4/0NzhP6pJdGmjWzet4SNe9gb1B3z3WV8wbbvnJVAbm4LM4hYUon57sIX3013/rIgyFqaDInKm6+ukGm35zwZGdpm1VWN8gLcumtdy1XB+kLtnNmW0O73g8Ebb2WmLhxF57LCorUGGniFE3p0kRPZ1hbnL344ctpI8+0zVqK/Nax7BPH7OBtZ8ZLAL09lcqVdfrDij1gWJly9EKLcaZXsEUYyaYTWtb3oVMaTLFb8mWJEzUi0x3lagzk9pke1IAR3fZI+JIzdmFmsqcEU79mlPm5+j3hL8WUFICsdX1tyElpP9lsUoisqNuKe/nwzRjuVYFqUJz9igWpodRZya18Vk01K9G5le1MURJqAPsHveUncOrAnNzaAJcqUHTtWT6sEME6U7i3h3jJEGtq+tl2SuLSMi1w0f3e+PoFjuTbwxBpSd7w53DqwLTednDkhtHXA/Iy1HLaqfEJl6c1U52hAnqnqvL3SeNySCffk5PvW0MQbqPSl+dTXXblkmS73694K8L7YXRUbYBXTxorVRYSRS9TA5Mx64vk4903//Wn9Zth2kMT03zx441jbvbuilB6vbp6f66bUBfXxqNcbNSyrcFBfDwmMCrMvnUdUnq6vL7PZKBWdUes+xifL2ANv3n/TfId+YRnq4N67MJ1cCylIVt45dhqFfN+slfDZjUNSWgM7LLOo1VBPeYlS7G1wlGzkjDi4ti5DvzYFE5wSIc2epTA9n+tNfwrIZRfC43C+a2wpIhf+Gh3aOlnw7rZp/ZP1R47Vs3T5F0ZFMUYjQWGI0lJ88XnOB3YfYoTR4e3OyZLRQZpf68v7YM8617fHDqYP2kW1Pm783zxdvLovH6fW2knw7rcD98wkd47Sem+EvtaW12KmlqIC//+OQAScMg+F0srZmFaibH+4/5Yusf2pTsl1iGqQLefLANTh02kuhWH4rPfO/oE1aSjx6W5i6ld7TpuTmEst2n0nv+WgWdWRaa0Gk1BvL3/M6OFoW61IrTR22QbaIt543JPCrcRvLR2fyV3cVo07PXjLLdp9J7/lpFSYlKWoAr3RSM7dLC72zvWCI7I9ZF5nX+lbgHFJ06MjssymCP+Z7u8bBWN70WgVcClZmNYOmUs7CceTr6G1Gz7aHSQoXJaW5W+dJpgowEc0oqshX1Be4BxYANP5dBLHL5rMZqtNz6OoAvLpPtWGjTqm2B5Onod4pg28OQ3tqcnrMnbYS+ZKeJusr8qlgdgjWg3+6OkO1fHtg1FsHOyXi88wFxOmgKyKDNSq4pc2f29gmSgcqV7Lshf1V77cwtk6U78qx2YbKTx6xewVe9vfzVyPzlOW0ls3H2/ASReV6OdmWi8jfWRtNXA0agqcBcyd5aFl3ttWyVOHBChvTUqavMr1rxxbNQQVJDWfImD+PeSiXm6LLiXjEV3um9FTP0uPCmDq0ktKHC6ro4l18LodG4G2FVrcxMqfhVyZztRSYHdJa2HU9+FCtdB64VaPS0ryYy5yWHTSDzOpg63AdTg/uHBskGAUoqKXcL2TGBW36qpF3gtQSt4GtYpW8g84YKJBmXORPZWIVFxXBwbrzyzavBlZS9vmReR29IJUsOq/mZT6IdnEZ637Mo/Wp6ZF5LIKvy08flOyc2DIzJXNv7nq31rqZH5o0oc5NQEKwIYmSR1fHKPqzXG7gpRES6K8b6aO1QVg2x2wHzSRoDN4LM46KthMkZNCHd5DI3Gfd2cKujhI+ZQuvNNnbXVhrJFUGl/ymqkzi0LJJgR6/zkY3bIuV6l3lMuA3WLHXDwPHpJpd5HZxb4yCrUN0mBdcSZDvTModSP6Fqkn9nafdRE5jWub3OZa4xvmVofcj82o541CPY9IrsVEI1vTObYVqQkiU7xX286hsmV3xG3R4eGyABlmsZ3Jb0lxErpWmWUsXPXjQPjwmQXQebEq4XmVvZlOKjVWd0zaLqU+Ymj68zUzEqzBY/fNBSuGZGFptq4hR3J2QfT/a4rAhWk7GoXin6IIPC79UUcS3JPCrMRlp6s8dlRdBUYx5OQ8i83hJq1i/TNkHiLtRsdsp+ME0NTE+IzjJM4z2f7YT0AiuEOCXh6D/2Yneycqix2JvrTeY5mWaIPWvYCeHSOStkpZmJ0jeUzE3u3BoDCwkWbtZGcLmfUlPNIGShyaLIUBy97IH3AjdhVm/jIfHaoCGc22tZ5rlZZvjtSw9EHLbFY+/HNZjMG8S5ZUbdjE6d5OAXbKrgPrfc3eQpu+0m+QEaE9eKzF+4sy3UZhDTpyFl3oCsDr+QSjY6+O3LqpuzNia4o6Hjpni8NKftNa3015LMX1saIzlGDS3zBk+aZ//2tT+44vhuOykyeH7huVrla5gaLFz+4PHypkxxUdbIybi2awkqolnmldEov/DFaGs52CuRnXmp+D2HZjXoDnzMqmSnLrbg27ep+q1Grwc0y9wQjTq1ce+mL17U7jLCbV16DjXcMM6rTaEUIpgCbDIaf85S92/2lidPfKOhWeYNyOpcLdgjMqCLabr3skZ13thANDQai9W5Wnx2g8i8xorfjGZcT2jO1WnGDYlmxW/GDYlmxW/GDYlmxW/GDYlmxW/GDYlmxW/GDYlmxW/GDYlmxW/GDYlmxW8GbkT8H8VVjnRRiynQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Verify the salient region\n",
    "# Below is an example call; you should show different wafer maps than example\n",
    "\n",
    "failure_types = df_train[\"failureType\"].unique()\n",
    "\n",
    "for ftype in failure_types:\n",
    "    example_row = df_train[df_train[\"failureType\"] == ftype].iloc[2]\n",
    "\n",
    "    wafer = example_row[\"waferMap_resized\"]\n",
    "    salient = example_row[\"salientRegion\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(2, 2))\n",
    "\n",
    "    axes[0].imshow(wafer)\n",
    "    #axes[0].set_title(f\"{ftype}  Original\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(salient)\n",
    "    #axes[1].set_title(f\"{ftype}  Salient Region\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the area of the salient region to the area of the wafer map\n",
    "def get_area_ratio(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]\n",
    "    wafer = row[\"waferMap_resized\"]\n",
    "\n",
    "    salient_area = np.sum(salient)\n",
    "\n",
    "    total_die_area = np.sum(wafer != 0)\n",
    "\n",
    "    if total_die_area == 0:\n",
    "        return 0.0\n",
    "    return  salient_area / total_die_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the perimeter of the salient region to the radius of the wafer map\n",
    "from skimage.measure import perimeter\n",
    "\n",
    "def get_perimeter_ratio(row: pd.Series) -> float:\n",
    "    \n",
    "    salient = row[\"salientRegion\"]     \n",
    "\n",
    "    perim = perimeter(salient, neighborhood=8)\n",
    "\n",
    "    radius = 32\n",
    "    \n",
    "    return perim / radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the maximal distance between the salient region and the center of the wafer map\n",
    "def get_max_dist_from_center(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]        \n",
    "\n",
    "    ys, xs = np.where(salient == 1)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    center_y = 31.5\n",
    "    center_x = 31.5\n",
    "\n",
    "    distances = np.sqrt((xs - center_x)**2 + (ys - center_y)**2)\n",
    "\n",
    "    return np.max(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the minimal distance between the salient region and the center of the wafer map\n",
    "def get_min_dist_from_center(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]        \n",
    "\n",
    "    ys, xs = np.where(salient == 1)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    center_y = 31.5\n",
    "    center_x = 31.5\n",
    "\n",
    "    distances = np.sqrt((xs - center_x)**2 + (ys - center_y)**2)\n",
    "    \n",
    "    return np.min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the length of the major axis of the estimated ellipse surrounding the salient region to the radius of the wafer map\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "def get_major_axis_ratio(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]\n",
    "\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    props = regionprops(salient.astype(int))\n",
    "\n",
    "    major_axis = props[0].major_axis_length\n",
    " \n",
    "    return major_axis / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the length of the minor axis of the estimated ellipse surrounding the salient region to the radius of the wafer map\n",
    "def get_minor_axis_ratio(row: pd.Series) -> float:\n",
    "    \n",
    "    salient = row[\"salientRegion\"]\n",
    "\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    props = regionprops(salient.astype(int))\n",
    "\n",
    "    minor_axis = props[0].minor_axis_length\n",
    " \n",
    "    return minor_axis / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the solidity, indicating the proportion of defective dies in the estimated convex hull of the salient region\n",
    "def get_solidity(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]\n",
    "\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    props = regionprops(salient.astype(int))\n",
    " \n",
    "    return props[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the eccentricity of the salient region\n",
    "def get_eccentricity(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]\n",
    "\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    props = regionprops(salient.astype(int))\n",
    " \n",
    "    return props[0].eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the failed dies on the wafer map to the total number of dies on the wafer map\n",
    "def get_yield_loss(row: pd.Series) -> float:\n",
    "    wafer = row[\"waferMap_resized\"]\n",
    "    fail = np.sum(wafer == 2)\n",
    "    total = np.sum(wafer != 0)  # only count valid die positions\n",
    "\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    return fail / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function that returns the ratio of the failed dies on the outermost two rings of the wafer map to the total number of dies on the outermost two rings of the wafer map\n",
    "# Use ring_label_from_outside helper function\n",
    "def get_edge_yield_loss(row: pd.Series) -> float:\n",
    "\n",
    "    wafer = row[\"waferMap_resized\"]\n",
    "\n",
    "    ring_mask = ring_label_from_outside(wafer)\n",
    "\n",
    "    ring_dies = wafer[ring_mask == 1]\n",
    "    valid_dies = ring_dies[ring_dies > 0]  \n",
    "\n",
    "    if len(valid_dies) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    fail_count = np.sum(valid_dies == 2)\n",
    "    total_count = len(valid_dies)\n",
    "\n",
    "    return fail_count / total_count\n",
    "\n",
    "\n",
    "# TODO: Implement a helper function that returns a numpy array highlighting the outermost two rings of the wafer map with nonzero value\n",
    "def ring_label_from_outside(wafer_map: np.ndarray) -> np.ndarray:\n",
    "    h, w = wafer_map.shape\n",
    "\n",
    "    y, x = np.indices((h, w))\n",
    "\n",
    "    dist_from_center = np.sqrt((x - 31.5)**2 + (y - 31.5)**2)\n",
    "\n",
    "    ring_mask = (dist_from_center >= 29.5) & (dist_from_center <= 32) #29.5 looks closer to example than 30\n",
    "\n",
    "    return ring_mask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Additional Feature Functions ====\n",
    "\n",
    "def radial_profile_features(img: np.ndarray, n_bins: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Compute radial failure density profile in n_bins between center and edge.\n",
    "    img: waferMap_resized (64x64), values in {0,1,2}\n",
    "    Returns a list of length n_bins.\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n",
    "\n",
    "    yy, xx = np.indices(img.shape)\n",
    "    r = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    max_r = r.max()\n",
    "\n",
    "    if max_r == 0:\n",
    "        return [0.0] * n_bins\n",
    "\n",
    "    r_norm = r / max_r\n",
    "\n",
    "    # consider only valid die locations (exclude NO_DIE)\n",
    "    valid_mask = (img != NO_DIE)\n",
    "    fail_mask = (img == FAIL)\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    feats = []\n",
    "    for i in range(n_bins):\n",
    "        bin_mask = (r_norm >= bins[i]) & (r_norm < bins[i + 1]) & valid_mask\n",
    "        if np.any(bin_mask):\n",
    "            feats.append(fail_mask[bin_mask].mean())\n",
    "        else:\n",
    "            feats.append(0.0)\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def angular_features(img: np.ndarray, slices: int = 16) -> list:\n",
    "    \"\"\"\n",
    "    Compute angular failure density in 'slices' angular bins.\n",
    "    img: waferMap_resized (64x64), values in {0,1,2}\n",
    "    Returns a list of length 'slices'.\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    cy, cx = (h - 1) / 2.0, (w - 1) / 2.0\n",
    "\n",
    "    yy, xx = np.indices(img.shape)\n",
    "    angles = np.arctan2(yy - cy, xx - cx)  # [-pi, pi]\n",
    "    angles_norm = (angles + np.pi) / (2 * np.pi)  # [0,1)\n",
    "\n",
    "    valid_mask = (img != NO_DIE)\n",
    "    fail_mask = (img == FAIL)\n",
    "\n",
    "    feats = []\n",
    "    for i in range(slices):\n",
    "        low = i / slices\n",
    "        high = (i + 1) / slices\n",
    "        bin_mask = (angles_norm >= low) & (angles_norm < high) & valid_mask\n",
    "        if np.any(bin_mask):\n",
    "            feats.append(fail_mask[bin_mask].mean())\n",
    "        else:\n",
    "            feats.append(0.0)\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def connected_components_features(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Compute connected component features on failing dies.\n",
    "    img: waferMap_resized (64x64), values in {0,1,2}\n",
    "    Returns [num_components, largest_component_ratio].\n",
    "    \"\"\"\n",
    "    fail_mask = (img == FAIL)\n",
    "    total_fails = fail_mask.sum()\n",
    "\n",
    "    if total_fails == 0:\n",
    "        return [0.0, 0.0]\n",
    "\n",
    "    labeled = label(fail_mask, connectivity=2)\n",
    "    if labeled.max() == 0:\n",
    "        return [0.0, 0.0]\n",
    "\n",
    "    # sizes of each component (ignore background at index 0)\n",
    "    sizes = np.bincount(labeled.ravel())[1:]\n",
    "    num_components = float(len(sizes))\n",
    "    largest = float(sizes.max())\n",
    "    largest_ratio = largest / float(total_fails) if total_fails > 0 else 0.0\n",
    "\n",
    "    return [num_components, largest_ratio]\n",
    "\n",
    "\n",
    "def texture_features(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Compute GLCM-based texture features on a binary failure mask.\n",
    "    img: waferMap_resized (64x64), values in {0,1,2}\n",
    "    Returns [contrast, energy, homogeneity].\n",
    "    \"\"\"\n",
    "    # binary image: 1 if FAIL, 0 otherwise\n",
    "    binary = (img == FAIL).astype(np.uint8)\n",
    "\n",
    "    # GLCM with 2 gray levels\n",
    "    glcm = graycomatrix(\n",
    "        binary,\n",
    "        distances=[2],\n",
    "        angles=[0],\n",
    "        levels=2,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "    return [float(contrast), float(energy), float(homogeneity)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Rotation-Invariant Additional Features ====\n",
    "\n",
    "def get_aspect_ratio(row: pd.Series) -> float:\n",
    "    \"\"\"Major/minor axis length ratio of salient region.\"\"\"\n",
    "    salient = row[\"salientRegion\"]\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "    props = regionprops(salient.astype(int))[0]\n",
    "    if props.minor_axis_length == 0:\n",
    "        return 0.0\n",
    "    return props.major_axis_length / props.minor_axis_length\n",
    "\n",
    "\n",
    "def get_thinness_ratio(row: pd.Series) -> float:\n",
    "    \"\"\"Thinness = (4 * area) / perimeter^2 (higher means more circular).\"\"\"\n",
    "    salient = row[\"salientRegion\"]\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    area = salient.sum()\n",
    "    peri = perimeter(salient, neighborhood=8)\n",
    "    \n",
    "    if peri == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return (4 * np.pi * area) / (peri ** 2)\n",
    "\n",
    "\n",
    "def get_convexity_ratio(row: pd.Series) -> float:\n",
    "    \"\"\"Convexity = area / convex_hull_area.\"\"\"\n",
    "    salient = row[\"salientRegion\"]\n",
    "    if np.sum(salient) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    props = regionprops(salient.astype(int))[0]\n",
    "    if props.convex_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return props.area / props.convex_area\n",
    "\n",
    "\n",
    "def get_circular_variance(row: pd.Series) -> float:\n",
    "    \"\"\"Rotation-invariant circular variance of failure angles.\"\"\"\n",
    "    img = row[\"waferMap_resized\"]\n",
    "    fail_mask = (img == FAIL)\n",
    "    ys, xs = np.where(fail_mask)\n",
    "    \n",
    "    if len(xs) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cy, cx = 31.5, 31.5\n",
    "    angles = np.arctan2(ys - cy, xs - cx)\n",
    "    \n",
    "    # circular variance = 1 - R (mean resultant length)\n",
    "    R = np.sqrt(np.mean(np.cos(angles))**2 + np.mean(np.sin(angles))**2)\n",
    "    return float(1 - R)\n",
    "\n",
    "\n",
    "def get_line_likeness(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Rotation-invariant line-likeness using PCA eigenvalue ratio.\n",
    "    Close to 1 means strong linear structure (scratch).\n",
    "    \"\"\"\n",
    "    img = row[\"waferMap_resized\"]\n",
    "    fail_mask = (img == FAIL)\n",
    "    ys, xs = np.where(fail_mask)\n",
    "    \n",
    "    if len(xs) < 3:\n",
    "        return 0.0\n",
    "    \n",
    "    coords = np.vstack([xs, ys]).T\n",
    "    cov = np.cov(coords.T)\n",
    "    eigenvals = np.linalg.eigvalsh(cov)\n",
    "    if eigenvals[0] <= 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return float(eigenvals[1] / eigenvals[0])  # 2 / 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "\n",
    "def get_hough_line_strength(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Computes the number of strong line peaks in the Hough transform.\n",
    "    Scratch wafers typically have 13 dominant peaks.\n",
    "    Others have 0 or very few.\n",
    "    \"\"\"\n",
    "    # binary fail mask\n",
    "    img = (row[\"waferMap_resized\"] == FAIL).astype(np.uint8)\n",
    "\n",
    "    # If no failures, no line\n",
    "    if img.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Hough transform\n",
    "    h, theta, dist = hough_line(img)\n",
    "\n",
    "    # Extract dominant peaks\n",
    "    _, angles, _ = hough_line_peaks(h, theta, dist, num_peaks=8)\n",
    "\n",
    "    # strength = number of detected line angles\n",
    "    return float(len(angles))\n",
    "\n",
    "def get_line_orientation_variance(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Computes variance of failure pixel angles relative to wafer center.\n",
    "    Scratch wafers have low variance (aligned line).\n",
    "    Random clusters have high variance.\n",
    "    \"\"\"\n",
    "    img = (row[\"waferMap_resized\"] == FAIL).astype(np.uint8)\n",
    "\n",
    "    ys, xs = np.where(img == 1)\n",
    "\n",
    "    # If too few points, not reliable\n",
    "    if len(xs) < 3:\n",
    "        return 0.0\n",
    "\n",
    "    cy, cx = 31.5, 31.5\n",
    "\n",
    "    # Compute angles [-pi, pi]\n",
    "    angles = np.arctan2(ys - cy, xs - cx)\n",
    "\n",
    "    # Circular variance:\n",
    "    # Use the vector strength to avoid wrap-around issues\n",
    "    R = np.sqrt(np.mean(np.cos(angles))**2 + np.mean(np.sin(angles))**2)\n",
    "    circular_var = 1 - R\n",
    "\n",
    "    return float(circular_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import probabilistic_hough_line\n",
    "\n",
    "def hough_line_features(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Hough-transform features for detecting straight-line patterns (Scratch).\n",
    "    Returns:\n",
    "        [num_lines, avg_length, max_length, angle_mean, angle_std]\n",
    "    \"\"\"\n",
    "    fail_mask = (img == FAIL).astype(np.uint8)\n",
    "\n",
    "    # run Hough transform\n",
    "    lines = probabilistic_hough_line(\n",
    "        fail_mask,\n",
    "        threshold=5,\n",
    "        line_length=6,\n",
    "        line_gap=2\n",
    "    )\n",
    "\n",
    "    if len(lines) == 0:\n",
    "        return [0, 0, 0, 0, 0]\n",
    "\n",
    "    # extract lengths + angles\n",
    "    lengths = []\n",
    "    angles = []\n",
    "\n",
    "    for (p0, p1) in lines:\n",
    "        dy = p1[1] - p0[1]\n",
    "        dx = p1[0] - p0[0]\n",
    "        length = np.sqrt(dx*dx + dy*dy)\n",
    "        angle = np.arctan2(dy, dx)\n",
    "\n",
    "        lengths.append(length)\n",
    "        angles.append(angle)\n",
    "\n",
    "    lengths = np.array(lengths)\n",
    "    angles = np.array(angles)\n",
    "\n",
    "    return [\n",
    "        float(len(lengths)),               # number of detected lines\n",
    "        float(lengths.mean()),             # average line length\n",
    "        float(lengths.max()),              # max line length\n",
    "        float(np.mean(angles)),            # mean angle\n",
    "        float(np.std(angles))              # angle spread\n",
    "    ]\n",
    "\n",
    "def ring_quadrant_features(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Failure densities in the 4 angular quadrants of the OUTER RING ONLY.\n",
    "    Returns length-4 list.\n",
    "    \"\"\"\n",
    "    # outer ring mask reuses your function\n",
    "    ring_mask = ring_label_from_outside(img)\n",
    "    fail_mask = (img == FAIL)\n",
    "\n",
    "    # coordinates\n",
    "    ys, xs = np.where(ring_mask == 1)\n",
    "\n",
    "    if len(xs) == 0:\n",
    "        return [0, 0, 0, 0]\n",
    "\n",
    "    cy, cx = 31.5, 31.5\n",
    "    angles = np.arctan2(ys - cy, xs - cx)  # [-pi, pi]\n",
    "\n",
    "    # 4 quadrants\n",
    "    feats = []\n",
    "    for k in range(4):\n",
    "        low = -np.pi + k * (np.pi/2)\n",
    "        high = -np.pi + (k+1) * (np.pi/2)\n",
    "        qmask = (angles >= low) & (angles < high)\n",
    "        if np.any(qmask):\n",
    "            feats.append(float(fail_mask[ys[qmask], xs[qmask]].mean()))\n",
    "        else:\n",
    "            feats.append(0.0)\n",
    "\n",
    "    return feats\n",
    "\n",
    "def connected_component_extended(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Extra connected-component statistics.\n",
    "    Returns: [mean_size, std_size, normalized_component_count]\n",
    "    \"\"\"\n",
    "    fail_mask = (img == FAIL)\n",
    "    total_fails = fail_mask.sum()\n",
    "\n",
    "    if total_fails == 0:\n",
    "        return [0, 0, 0]\n",
    "\n",
    "    labeled = label(fail_mask, connectivity=2)\n",
    "    comp_sizes = np.bincount(labeled.ravel())[1:]\n",
    "\n",
    "    if len(comp_sizes) == 0:\n",
    "        return [0, 0, 0]\n",
    "\n",
    "    mean_sz = float(comp_sizes.mean())\n",
    "    std_sz = float(comp_sizes.std())\n",
    "    norm_count = float(len(comp_sizes)) / float(total_fails)\n",
    "\n",
    "    return [mean_sz, std_sz, norm_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadrant_failure_ratios(img: np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    Returns fail ratios in 4 quadrants:\n",
    "    Q1 | Q2\n",
    "    ----+----\n",
    "    Q3 | Q4\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    mid_y, mid_x = h // 2, w // 2\n",
    "\n",
    "    fail = (img == FAIL).astype(int)\n",
    "    valid = (img != NO_DIE).astype(int)\n",
    "\n",
    "    Q1 = fail[:mid_y, :mid_x].sum() / max(1, valid[:mid_y, :mid_x].sum())\n",
    "    Q2 = fail[:mid_y, mid_x:].sum() / max(1, valid[:mid_y, mid_x:].sum())\n",
    "    Q3 = fail[mid_y:, :mid_x].sum() / max(1, valid[mid_y:, :mid_x].sum())\n",
    "    Q4 = fail[mid_y:, mid_x:].sum() / max(1, valid[mid_y:, mid_x:].sum())\n",
    "\n",
    "    return [Q1, Q2, Q3, Q4]\n",
    "\n",
    "def radial_slope(radials: list) -> float:\n",
    "    \"\"\"Simple slope: outer - inner.\"\"\"\n",
    "    return float(radials[-1] - radials[0])\n",
    "\n",
    "def radial_curvature(radials: list) -> float:\n",
    "    \"\"\"Second difference: r4 - 2*r2 + r0.\"\"\"\n",
    "    if len(radials) < 5:\n",
    "        return 0.0\n",
    "    return float(radials[4] - 2*radials[2] + radials[0])\n",
    "def get_elongation(row: pd.Series) -> float:\n",
    "    salient = row[\"salientRegion\"]\n",
    "    if salient.sum() == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    props = regionprops(salient.astype(int))[0]\n",
    "    minor = props.minor_axis_length\n",
    "    major = props.major_axis_length\n",
    "    \n",
    "    if minor == 0:\n",
    "        return 0.0\n",
    "    return float(major / minor)\n",
    "\n",
    "def quadrant_component_counts(img: np.ndarray) -> list:\n",
    "    fail = (img == FAIL).astype(int)\n",
    "    h, w = img.shape\n",
    "    mid_y, mid_x = h // 2, w // 2\n",
    "\n",
    "    def count_comp(region):\n",
    "        lab = label(region, connectivity=2)\n",
    "        return int(lab.max())\n",
    "\n",
    "    Q1 = count_comp(fail[:mid_y, :mid_x])\n",
    "    Q2 = count_comp(fail[:mid_y, mid_x:])\n",
    "    Q3 = count_comp(fail[mid_y:, :mid_x])\n",
    "    Q4 = count_comp(fail[mid_y:, mid_x:])\n",
    "\n",
    "    return [Q1, Q2, Q3, Q4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "pasgTNWn_MfB"
   },
   "outputs": [],
   "source": [
    "def create_feature_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # ===== Existing Features =====\n",
    "    df['areaRatio'] = df.apply(get_area_ratio, axis=1)\n",
    "    df['perimeterRatio'] = df.apply(get_perimeter_ratio, axis=1)\n",
    "    df['maxDistFromCenter'] = df.apply(get_max_dist_from_center, axis=1)\n",
    "    df['minDistFromCenter'] = df.apply(get_min_dist_from_center, axis=1)\n",
    "    df['majorAxisRatio'] = df.apply(get_major_axis_ratio, axis=1)\n",
    "    df['minorAxisRatio'] = df.apply(get_minor_axis_ratio, axis=1)\n",
    "    df['solidity'] = df.apply(get_solidity, axis=1)\n",
    "    df['eccentricity'] = df.apply(get_eccentricity, axis=1)\n",
    "    df['yieldLoss'] = df.apply(get_yield_loss, axis=1)\n",
    "    df['edgeYieldLoss'] = df.apply(get_edge_yield_loss, axis=1)\n",
    "\n",
    "    # ===== NEW FEATURES: Radial Profile (5 bins) =====\n",
    "    radial_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        radial_profile_features(img),\n",
    "        index=[f\"radial_{i}\" for i in range(5)]\n",
    "    ))\n",
    "    df = pd.concat([df, radial_df], axis=1)\n",
    "\n",
    "    # ===== NEW FEATURES: Angular Histogram (8 bins) =====\n",
    "    ang_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        angular_features(img),\n",
    "        index=[f\"ang_{i}\" for i in range(16)]\n",
    "    ))\n",
    "    df = pd.concat([df, ang_df], axis=1)\n",
    "\n",
    "    # ===== NEW FEATURES: Connected Components (2) =====\n",
    "    comp_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        connected_components_features(img),\n",
    "        index=[\"numComponents\", \"largestComponentRatio\"]\n",
    "    ))\n",
    "    df = pd.concat([df, comp_df], axis=1)\n",
    "\n",
    "    # ===== NEW FEATURES: GLCM Texture (3) =====\n",
    "    glcm_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        texture_features(img),\n",
    "        index=[\"glcm_contrast\", \"glcm_energy\", \"glcm_homogeneity\"]\n",
    "    ))\n",
    "    df = pd.concat([df, glcm_df], axis=1)\n",
    "\n",
    "    # ===== NEW FEATURES: Rotation-Invariant Shape Measures (5) =====\n",
    "    df['aspectRatio']       = df.apply(get_aspect_ratio, axis=1)\n",
    "    df['thinnessRatio']     = df.apply(get_thinness_ratio, axis=1)\n",
    "    df['convexityRatio']    = df.apply(get_convexity_ratio, axis=1)\n",
    "    df['circularVariance']  = df.apply(get_circular_variance, axis=1)\n",
    "    df['lineLikeness']      = df.apply(get_line_likeness, axis=1)\n",
    "\n",
    "        # ===== ADD HOUGH + ANGLE VARIANCE HERE =====\n",
    "    df['houghLineStrength'] = df.apply(get_hough_line_strength, axis=1)\n",
    "    df['lineOrientationVariance'] = df.apply(get_line_orientation_variance, axis=1)\n",
    "\n",
    "    hough_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        hough_line_features(img),\n",
    "        index=[\"hough_num\", \"hough_avg_len\", \"hough_max_len\", \"hough_angle_mean\", \"hough_angle_std\"]\n",
    "    ))\n",
    "    df = pd.concat([df, hough_df], axis=1)\n",
    "\n",
    "    # ===== Outer Ring Quadrant Failure Density (4) =====\n",
    "    ringq_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        ring_quadrant_features(img),\n",
    "        index=[\"ringQ1\", \"ringQ2\", \"ringQ3\", \"ringQ4\"]\n",
    "    ))\n",
    "    df = pd.concat([df, ringq_df], axis=1)\n",
    "\n",
    "    # ===== Extended Connected Component Stats (3) =====\n",
    "    comp_ext_df = df['waferMap_resized'].apply(lambda img: pd.Series(\n",
    "        connected_component_extended(img),\n",
    "        index=[\"comp_mean_size\", \"comp_std_size\", \"comp_norm_count\"]\n",
    "    ))\n",
    "    df = pd.concat([df, comp_ext_df], axis=1)\n",
    "\n",
    "    # ==== NEW FEATURES ONLY ====\n",
    "\n",
    "    # 1. Radial Slope + Curvature\n",
    "    df[\"radialSlope\"] = radial_df.apply(lambda x: radial_slope(list(x.values)), axis=1)\n",
    "    df[\"radialCurvature\"] = radial_df.apply(lambda x: radial_curvature(list(x.values)), axis=1)\n",
    "\n",
    "    # 2. Quadrant Failure Ratios (4 features)\n",
    "    quad_fail_df = df['waferMap_resized'].apply(\n",
    "        lambda img: pd.Series(\n",
    "            quadrant_failure_ratios(img),\n",
    "            index=[\"quadFail_Q1\", \"quadFail_Q2\", \"quadFail_Q3\", \"quadFail_Q4\"]\n",
    "        )\n",
    "    )\n",
    "    df = pd.concat([df, quad_fail_df], axis=1)\n",
    "\n",
    "    # 3. Quadrant Component Counts (4 features)\n",
    "    quad_comp_df = df['waferMap_resized'].apply(\n",
    "        lambda img: pd.Series(\n",
    "            quadrant_component_counts(img),\n",
    "            index=[\"quadComp_Q1\", \"quadComp_Q2\", \"quadComp_Q3\", \"quadComp_Q4\"]\n",
    "        )\n",
    "    )\n",
    "    df = pd.concat([df, quad_comp_df], axis=1)\n",
    "\n",
    "    # 4. Elongation (major/minor axis)\n",
    "    df[\"elongation\"] = df.apply(get_elongation, axis=1)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Helper: Generate augmented versions of an image\n",
    "# ---------------------------------------------\n",
    "def augment_image(img):\n",
    "    \"\"\"Return list of augmented images (NO FEATURE COMPUTATION HERE).\"\"\"\n",
    "    aug = [\n",
    "        np.rot90(img, 1),\n",
    "        np.rot90(img, 2),\n",
    "        np.rot90(img, 3),\n",
    "        np.flipud(img),\n",
    "        np.fliplr(img),\n",
    "        rotate(img, angle=np.random.uniform(-10, 10), order=0,\n",
    "               preserve_range=True).astype(img.dtype)\n",
    "    ]\n",
    "    return aug\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Augment training data BEFORE feature creation (correct way!)\n",
    "# -------------------------------------------------------------\n",
    "def prepare_augmented_data(df: pd.DataFrame, min_samples: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Augments underrepresented classes to reach at least min_samples.\n",
    "    Only modifies waferMap + waferMap_resized + failureType_num.\n",
    "    Does NOT compute features  feature extraction happens later.\n",
    "    \"\"\"\n",
    "    print(\"=== Running data augmentation BEFORE feature creation ===\")\n",
    "\n",
    "    # Add flag if missing\n",
    "    if \"isAugmented\" not in df.columns:\n",
    "        df[\"isAugmented\"] = False\n",
    "\n",
    "    # Count per class\n",
    "    total_counts = df[\"failureType\"].value_counts()\n",
    "    print(\"Current total counts:\")\n",
    "    print(total_counts)\n",
    "\n",
    "    # Identify classes that need augmentation\n",
    "    minority_classes = [cls for cls, cnt in total_counts.items() if cnt < min_samples]\n",
    "    print(\"Classes needing augmentation:\", minority_classes)\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    for cls in minority_classes:\n",
    "        current_total = total_counts[cls]\n",
    "        needed = min_samples - current_total\n",
    "\n",
    "        print(f\"Augmenting '{cls}'  need {needed} samples\")\n",
    "\n",
    "        # Only original rows should be augmented\n",
    "        originals = df[(df[\"failureType\"] == cls) & (df[\"isAugmented\"] == False)]\n",
    "\n",
    "        for _, row in originals.iterrows():\n",
    "            if needed <= 0:\n",
    "                break\n",
    "\n",
    "            # Make augmented versions of this wafer\n",
    "            for img_aug in augment_image(row[\"waferMap\"]):\n",
    "                if needed <= 0:\n",
    "                    break\n",
    "\n",
    "                new_row = row.copy()\n",
    "\n",
    "                # Replace only the image + resized image\n",
    "                new_row[\"waferMap\"] = img_aug\n",
    "                new_row[\"waferMap_resized\"] = resize_wafer_map(img_aug)\n",
    "\n",
    "                # Copy numeric label\n",
    "                new_row[\"failureType_num\"] = convert_failure_type(new_row[\"failureType\"])\n",
    "\n",
    "                # Mark as augmented\n",
    "                new_row[\"isAugmented\"] = True\n",
    "\n",
    "                augmented_rows.append(new_row)\n",
    "                needed -= 1\n",
    "\n",
    "    # Append new rows\n",
    "    if augmented_rows:\n",
    "        df_aug = pd.DataFrame(augmented_rows)\n",
    "        df = pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "    print(\"New total training size:\", len(df))\n",
    "    print(\"Counts after augmentation:\")\n",
    "    print(df[\"failureType\"].value_counts())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = prepare_augmented_data(df_train)     # augment first\n",
    "\n",
    "df_train[\"salientRegion\"] = df_train.apply(get_salient_region, axis=1)\n",
    "df_train = create_feature_columns(df_train)     # THEN compute features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class XGBWithEarlyStopping(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "        self.estimator = XGBClassifier(\n",
    "            **{k: v for k, v in params.items() if k != \"early_stopping_rounds\"},\n",
    "            eval_metric=\"mlogloss\",\n",
    "            tree_method=\"hist\",\n",
    "            objective=\"multi:softprob\"\n",
    "        )\n",
    "        self.early_stopping_rounds = params.get(\"early_stopping_rounds\", 20)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Build a validation set using 20% split INSIDE each CV fold\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        self.estimator.set_params(**{k: v for k, v in self.params.items() if k != \"early_stopping_rounds\"})\n",
    "        \n",
    "        self.estimator.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            verbose=False\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# from xgboost.callback import EarlyStopping\n",
    "\n",
    "\n",
    "# def run_model_grid_search(X, y):\n",
    "\n",
    "#     print(\"=== Starting Multi-Model Grid Search ===\")\n",
    "\n",
    "#     models_and_grids = {\n",
    "\n",
    "#         # ---------------------------\n",
    "#         # 1. SVM (RBF)\n",
    "#         # ---------------------------\n",
    "#         \"SVM_RBF\": (\n",
    "#             SVC(probability=False),\n",
    "#             {\n",
    "#                 \"kernel\": [\"rbf\"],\n",
    "#                 \"C\": [0.1, 1, 10, 50],\n",
    "#                 \"gamma\": [\"scale\", 0.3, 0.1, 0.01, 0.001]\n",
    "#             }\n",
    "#         ),\n",
    "\n",
    "#         # ---------------------------\n",
    "#         # 2. RandomForest\n",
    "#         # ---------------------------\n",
    "#         \"RandomForest\": (\n",
    "#             RandomForestClassifier(),\n",
    "#             {\n",
    "#                 \"n_estimators\": [100, 200, 400],\n",
    "#                 \"max_depth\": [5, 10, 20],\n",
    "#                 \"min_samples_split\": [2, 5],\n",
    "#                 \"min_samples_leaf\": [1, 2]\n",
    "#             }\n",
    "#         ),\n",
    "\n",
    "#         # ---------------------------\n",
    "#         # 3. XGBoost  (with regularization!)\n",
    "#         # ---------------------------\n",
    "#         \"XGBoost\": (\n",
    "#             XGBClassifier(\n",
    "                \n",
    "#                 eval_metric=\"mlogloss\",\n",
    "#                 tree_method=\"hist\",\n",
    "#                 objective=\"multi:softprob\"\n",
    "        \n",
    "#             ),\n",
    "        \n",
    "#             {\n",
    "#                 # # Core parameters\n",
    "#                 # \"n_estimators\": [200, 350],                # moderate + slightly larger\n",
    "#                 # \"learning_rate\": [0.05, 0.1],             # stable + slightly faster\n",
    "#                 # \"max_depth\": [3, 6, 9],                   # shallow / medium / deep\n",
    "\n",
    "#                 # # Sampling parameters (diverse but small grid)\n",
    "#                 # \"subsample\": [0.8, 1.0],\n",
    "#                 # \"colsample_bytree\": [0.8, 1.0],\n",
    "\n",
    "#                 # # Regularization parameters (kept small but meaningful)\n",
    "#                 # \"min_child_weight\": [1, 4],               # low + medium\n",
    "#                 # \"gamma\": [0, 0.2],                        # no pruning vs light pruning\n",
    "#                 # \"reg_alpha\": [0, 0.5],                    # L1 penalty: off / light\n",
    "#                 # \"reg_lambda\": [1.0]                       # fix L2 penalty to reduce grid\n",
    "\n",
    "              \n",
    "#                 \"n_estimators\": [350, 500],\n",
    "#                 \"max_depth\": [3, 5, 7, 9],\n",
    "#                 \"learning_rate\": [0.05, 0.1],\n",
    "\n",
    "#                 \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "#                 \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "\n",
    "#                 \"min_child_weight\": [1, 3, 5, 8],\n",
    "#                 \"gamma\": [0, 0.1, 0.3, 0.5],\n",
    "\n",
    "#                 \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
    "#                 \"reg_lambda\": [0.5, 1.0, 2.0],\n",
    "\n",
    "#                 \"grow_policy\": [\"depthwise\", \"lossguide\"],\n",
    "#                 \"max_leaves\": [31, 63],     # only used if lossguide\n",
    "\n",
    "#                 \"max_bin\": [128, 256],\n",
    "\n",
    "\n",
    "#             }\n",
    "#         ),\n",
    "\n",
    "\n",
    "#         # ---------------------------\n",
    "#         # 4. Logistic Regression\n",
    "#         # ---------------------------\n",
    "#         \"LogisticRegression\": (\n",
    "#             LogisticRegression(max_iter=500, multi_class=\"auto\"),\n",
    "#             {\n",
    "#                 \"C\": [0.1, 1, 5, 10],\n",
    "#                 \"penalty\": [\"l2\"]\n",
    "#             }\n",
    "#         ),\n",
    "\n",
    "#         # ---------------------------\n",
    "#         # 5. MLP Neural Network\n",
    "#         # ---------------------------\n",
    "#         \"MLP\": (\n",
    "#             MLPClassifier(max_iter=300),\n",
    "#             {\n",
    "#                 \"hidden_layer_sizes\": [(64,), (128,), (128, 64)],\n",
    "#                 \"learning_rate_init\": [0.001, 0.01],\n",
    "#                 \"alpha\": [0.0001, 0.001]\n",
    "#             }\n",
    "#         ),\n",
    "#     }\n",
    "\n",
    "#     best_model = None\n",
    "#     best_score = -1\n",
    "#     best_name = None\n",
    "#     best_params = None\n",
    "\n",
    "#     for name, (model, grid) in models_and_grids.items():\n",
    "#         print(f\"\\n=== Searching {name} ===\")\n",
    "#         gs = GridSearchCV(\n",
    "#             model,\n",
    "#             grid,\n",
    "#             cv=5,\n",
    "#             scoring=\"accuracy\",\n",
    "#             n_jobs=-1\n",
    "#         )\n",
    "#         gs.fit(X, y)\n",
    "\n",
    "#         print(f\"> Best {name} validation accuracy: {gs.best_score_:.4f}\")\n",
    "#         print(f\"> Best hyperparameters: {gs.best_params_}\")\n",
    "\n",
    "#         if name == \"XGBoost\": #gs.best_score_ > best_score: #testing\n",
    "#             best_score = gs.best_score_\n",
    "#             best_model = gs.best_estimator_\n",
    "#             best_name = name\n",
    "#             best_params = gs.best_params_\n",
    "\n",
    "#     print(\"\\n========================================\")\n",
    "#     print(\" BEST OVERALL MODEL FOUND \")\n",
    "#     print(\"========================================\")\n",
    "#     print(f\"Model: {best_name}\")\n",
    "#     print(f\"Validation Accuracy: {best_score:.4f}\")\n",
    "#     print(f\"Params: {best_params}\")\n",
    "\n",
    "#     return best_model, best_name, best_score, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def run_model_grid_search(X, y):\n",
    "\n",
    "    print(\"=== Starting FAST Multi-Model Grid Search (30 minutes max) ===\")\n",
    "\n",
    "    models_and_grids = {\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 1. FAST SVM (small grid)\n",
    "        # ------------------------------------------------------------\n",
    "        \"SVM_RBF\": (\n",
    "            SVC(),\n",
    "            {\n",
    "                \"C\": [1, 10],\n",
    "                \"gamma\": [\"scale\", 0.01],\n",
    "                \"kernel\": [\"rbf\"]\n",
    "            }\n",
    "        ),\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 2. Tiny RandomForest\n",
    "        # ------------------------------------------------------------\n",
    "        \"RandomForest\": (\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                \"n_estimators\": [200],\n",
    "                \"max_depth\": [10, None],\n",
    "                \"min_samples_split\": [2],\n",
    "            }\n",
    "        ),\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 3. XGBoost (slimmed grid)\n",
    "        # ------------------------------------------------------------\n",
    "        \"XGBoost\": (\n",
    "            XGBClassifier(\n",
    "                eval_metric=\"mlogloss\",\n",
    "                tree_method=\"hist\",\n",
    "                objective=\"multi:softprob\",\n",
    "                use_label_encoder=False,\n",
    "            ),\n",
    "            {\n",
    "                \"n_estimators\": [350],\n",
    "                \"max_depth\": [4, 6, 9],\n",
    "                \"learning_rate\": [0.1],\n",
    "                \"subsample\": [0.8, 1.0],\n",
    "                \"colsample_bytree\": [0.8, 1.0],\n",
    "                \"gamma\": [0, 0.2],\n",
    "                \"min_child_weight\": [1, 3],\n",
    "                \"reg_alpha\": [0, 0.1],\n",
    "                \"reg_lambda\": [0.5, 1.0],\n",
    "            }\n",
    "        ),\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 4. LightGBM (fast + strong)\n",
    "        # ------------------------------------------------------------\n",
    "        \"LightGBM\": (\n",
    "            LGBMClassifier(\n",
    "                objective=\"multiclass\",\n",
    "                verbosity=-1        # <-- suppresses LightGBM warnings!\n",
    "            ),\n",
    "            {\n",
    "                \"n_estimators\": [400, 600],\n",
    "                \"learning_rate\": [0.05],\n",
    "                \"max_depth\": [-1, 6],\n",
    "                \"num_leaves\": [31, 63],\n",
    "                \"subsample\": [0.8, 1.0],\n",
    "                \"colsample_bytree\": [0.8, 1.0],\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -1\n",
    "    best_name = None\n",
    "    best_params = None\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # MODEL SEARCH LOOP\n",
    "    # ------------------------------------------------------------\n",
    "    for name, (model, grid) in models_and_grids.items():\n",
    "        print(f\"\\n=== Searching {name} (Reduced Grid) ===\")\n",
    "\n",
    "        gs = GridSearchCV(\n",
    "            model,\n",
    "            grid,\n",
    "            cv=3,                 #  makes everything 4050% faster\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        gs.fit(X, y)\n",
    "\n",
    "        print(f\"> Best {name} accuracy: {gs.best_score_:.4f}\")\n",
    "        print(f\"> Best params: {gs.best_params_}\")\n",
    "\n",
    "        if gs.best_score_ > best_score:\n",
    "            best_score = gs.best_score_\n",
    "            best_model = gs.best_estimator_\n",
    "            best_name = name\n",
    "            best_params = gs.best_params_\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # PRINT RESULTS\n",
    "    # ------------------------------------------------------------\n",
    "    print(\"\\n========================================\")\n",
    "    print(\" BEST OVERALL MODEL FOUND (FAST SEARCH)\")\n",
    "    print(\"========================================\")\n",
    "    print(f\"Model: {best_name}\")\n",
    "    print(f\"Accuracy: {best_score:.4f}\")\n",
    "    print(f\"Params: {best_params}\")\n",
    "\n",
    "    return best_model, best_name, best_score, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2VztqCQ_MfB",
    "outputId": "7cdbd2ad-356c-4b8b-839b-b11c1eec611d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used: 66\n",
      "Original class counts: [ 771  388 1159   15  413]\n",
      "Remaining NaNs: 0\n",
      "After SMOTE: [ 771  388 1159   15  413]\n",
      "\n",
      "Training distribution:\n",
      "2    927\n",
      "0    617\n",
      "4    330\n",
      "1    310\n",
      "3     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation distribution:\n",
      "2    232\n",
      "0    154\n",
      "4     83\n",
      "1     78\n",
      "3      3\n",
      "Name: count, dtype: int64\n",
      "=== Starting FAST Multi-Model Grid Search (30 minutes max) ===\n",
      "\n",
      "=== Searching SVM_RBF (Reduced Grid) ===\n",
      "> Best SVM_RBF accuracy: 0.9818\n",
      "> Best params: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "=== Searching RandomForest (Reduced Grid) ===\n",
      "> Best RandomForest accuracy: 0.9745\n",
      "> Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "=== Searching XGBoost (Reduced Grid) ===\n",
      "> Best XGBoost accuracy: 0.9795\n",
      "> Best params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 350, 'reg_alpha': 0, 'reg_lambda': 0.5, 'subsample': 0.8}\n",
      "\n",
      "=== Searching LightGBM (Reduced Grid) ===\n",
      "> Best LightGBM accuracy: 0.9795\n",
      "> Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 600, 'num_leaves': 63, 'subsample': 0.8}\n",
      "\n",
      "========================================\n",
      " BEST OVERALL MODEL FOUND (FAST SEARCH)\n",
      "========================================\n",
      "Model: SVM_RBF\n",
      "Accuracy: 0.9818\n",
      "Params: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "=== FINAL MODEL FIT COMPLETE ===\n",
      "Best model: SVM_RBF\n",
      "Best score: 0.9818\n",
      "Best params: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# === FEATURE SELECTION + SMOTE + TRAIN/VALID SPLIT (CLEAN) ===\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Select usable feature columns\n",
    "# ------------------------------------------------------------\n",
    "feature_cols = [\n",
    "    c for c in df_train.columns\n",
    "    if c not in (\n",
    "        \"waferMap\", \"waferMap_resized\", \"salientRegion\",\n",
    "        \"failureType\", \"failureType_num\", \"dieSize\",\n",
    "        \"lotName\", \"trainTestLabel\", \"waferIndex\", \"isAugmented\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Number of features used: {len(feature_cols)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Extract X, y\n",
    "# ------------------------------------------------------------\n",
    "X = df_train[feature_cols].values\n",
    "y = df_train[\"failureType_num\"].values\n",
    "\n",
    "print(\"Original class counts:\", np.bincount(y))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Apply SMOTE ONLY to minority class (Near-full = class 3)\n",
    "# ------------------------------------------------------------\n",
    "target_samples = 400\n",
    "sampling_strategy = {3: target_samples}   # only boost Near-full\n",
    "\n",
    "# sm = SMOTE(\n",
    "#     sampling_strategy=sampling_strategy,\n",
    "#     k_neighbors=3,\n",
    "#     random_state=RANDOM_SEED\n",
    "# )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.5 Handle missing values BEFORE SMOTE\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# (Optional sanity check)\n",
    "print(\"Remaining NaNs:\", np.isnan(X).sum())\n",
    "\n",
    "\n",
    "#X_resampled, y_resampled = sm.fit_resample(X, y)\n",
    "\n",
    "X_resampled, y_resampled = X, y # Skip SMOTE for faster testing\n",
    "\n",
    "print(\"After SMOTE:\", np.bincount(y_resampled))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Train/Validation split (BEFORE SCALING  correct method)\n",
    "# ------------------------------------------------------------\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_resampled\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Standardization (fit ONLY on training  no leakage)\n",
    "# ------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "\n",
    "print(\"\\nTraining distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "print(\"\\nValidation distribution:\")\n",
    "print(pd.Series(y_valid).value_counts())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. GRID SEARCH USING PROPERLY SCALED TRAIN SET\n",
    "# ------------------------------------------------------------\n",
    "best_model, best_name, best_score, best_params = run_model_grid_search(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. REFIT BEST MODEL ON FULL (RESAMPLED + SCALED) DATA\n",
    "# ------------------------------------------------------------\n",
    "# Scale the full resampled dataset using the SAME scaler\n",
    "#X_resampled = scaler.transform(X_resampled)\n",
    "X_resampled = scaler.transform(X_resampled) #no SMOTE\n",
    "\n",
    "#best_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "\n",
    "print(\"\\n=== FINAL MODEL FIT COMPLETE ===\")\n",
    "print(f\"Best model: {best_name}\")\n",
    "print(f\"Best score: {best_score:.4f}\")\n",
    "print(f\"Best params: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "CFYVm7y0_MfB",
    "outputId": "98ee2e4a-c1e9-4b3c-f511-1d7a63520e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2196, 66)\n",
      "Validation set shape: (550, 66)\n",
      "\n",
      "Training distribution:\n",
      "0    617\n",
      "1    310\n",
      "2    927\n",
      "3     12\n",
      "4    330\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation distribution:\n",
      "0    154\n",
      "1     78\n",
      "2    232\n",
      "3      3\n",
      "4     83\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: check train/validation distribution\n",
    "\n",
    "train_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "valid_counts = pd.Series(y_valid).value_counts().sort_index()\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_valid.shape)\n",
    "\n",
    "print(\"\\nTraining distribution:\")\n",
    "print(train_counts)\n",
    "\n",
    "print(\"\\nValidation distribution:\")\n",
    "print(valid_counts)\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.bar(train_counts.index - 0.2, train_counts.values, width=0.4, label='Train')\n",
    "# plt.bar(valid_counts.index + 0.2, valid_counts.values, width=0.4, label='Validation')\n",
    "# plt.xlabel(\"Failure Type (numeric label)\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"Class Distribution in Train vs Validation Split\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "TeVmSS3i_MfC"
   },
   "outputs": [],
   "source": [
    "# TODO: Make a dictionary that is the reverse of the string2int mapping defined above.\n",
    "int2string = {\n",
    "    0: 'Center',\n",
    "    1: 'Donut',\n",
    "    2: 'Edge-Loc',\n",
    "    3: 'Near-full',\n",
    "    4: 'Scratch'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features from training: 66\n",
      "df_test has: 66 matching columns\n"
     ]
    }
   ],
   "source": [
    "# === 1. Load test ===\n",
    "data_test = np.load(\"data/wafermap_test.npy\", allow_pickle=True)\n",
    "df_test = pd.DataFrame({name: data_test[name] for name in data_test.dtype.names})\n",
    "\n",
    "# === 2. Prepare test (resize only) ===\n",
    "df_test, _ = prepare_data(df_test, has_labels=False)\n",
    "\n",
    "# === 3. Salient region ===\n",
    "df_test[\"salientRegion\"] = df_test.apply(get_salient_region, axis=1)\n",
    "\n",
    "# === 4. Create ALL features (MUST BE BEFORE BUILDING feature_cols list) ===\n",
    "df_test = create_feature_columns(df_test)\n",
    "\n",
    "\n",
    "print(\"Features from training:\", len(feature_cols))\n",
    "print(\"df_test has:\", sum(c in df_test.columns for c in feature_cols), \"matching columns\")\n",
    "\n",
    "# === 6. Build X_test using VERIFIED columns ===\n",
    "#X_test = df_test[feature_cols].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing in test: []\n",
      "66\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "missing_in_test = [c for c in feature_cols if c not in df_test.columns]\n",
    "print(\"missing in test:\", missing_in_test)\n",
    "\n",
    "print(len(feature_cols))\n",
    "print(df_test.columns.size)\n",
    "#df_test = create_feature_columns(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-Class Accuracy (Validation Set) ===\n",
      "Center     : 0.9870 (152/154)\n",
      "Donut      : 0.9487 (74/78)\n",
      "Edge-Loc   : 0.9957 (231/232)\n",
      "Near-full  : 1.0000 (3/3)\n",
      "Scratch    : 0.9518 (79/83)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Validation predictions using the best model BEFORE refitting on full data\n",
    "y_pred_valid = best_model.predict(X_valid)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_valid)\n",
    "\n",
    "print(\"\\n=== Per-Class Accuracy (Validation Set) ===\")\n",
    "for label in range(len(int2string)):\n",
    "    correct = cm[label, label]\n",
    "    total = cm[label].sum()\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    print(f\"{int2string[label]:<10} : {acc:.4f} ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if best_name == \"XGBoost\":\n",
    "    importances = best_model.feature_importances_\n",
    "    feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)\n",
    "    print(feat_imp.head(20))\n",
    "    print(feat_imp.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Selecting features by importance ===\n",
      "No feature selection for non-XGBoost models.\n",
      "\n",
      "Shapes after feature selection:\n",
      "X_train: (2196, 66)\n",
      "X_valid: (550, 66)\n",
      "\n",
      "=== Per-Class Accuracy (AFTER Feature Selection) ===\n",
      "Center     : 0.9870 (152/154)\n",
      "Donut      : 0.9487 (74/78)\n",
      "Edge-Loc   : 0.9957 (231/232)\n",
      "Near-full  : 1.0000 (3/3)\n",
      "Scratch    : 0.9518 (79/83)\n",
      "Total validation accuracy: 0.9800\n",
      "scores.csv saved with selected features!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# === REMOVE LOW-IMPORTANCE FEATURES BEFORE FINAL TRAINING ===\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Selecting features by importance ===\")\n",
    "\n",
    "# 1. Get importances from the best model chosen by grid search\n",
    "if best_name == \"XGBoost\":\n",
    "    importances = best_model.feature_importances_\n",
    "\n",
    "    # 2. Threshold  tuneable (0.003 is good for your dataset)\n",
    "    THRESH = 0.003\n",
    "\n",
    "    # 3. Build list of important features\n",
    "    important_mask = importances >= THRESH\n",
    "    important_features = [\n",
    "        f for f, keep in zip(feature_cols, important_mask) if keep\n",
    "    ]\n",
    "\n",
    "    print(f\"Total features before: {len(feature_cols)}\")\n",
    "    print(f\"Total features kept:   {len(important_features)}\")\n",
    "    print(\"Kept features:\")\n",
    "    print(important_features)\n",
    "\n",
    "    # 4. Rebuild X and y using ONLY important features\n",
    "    X = df_train[important_features].values\n",
    "    y = df_train[\"failureType_num\"].values\n",
    "\n",
    "    # 5. Reapply imputer (IMPORTANT  do not reuse old one)\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X = imputer.fit_transform(X)\n",
    "else:\n",
    "    print(\"No feature selection for non-XGBoost models.\")\n",
    "    important_features = feature_cols  # keep all features\n",
    "    X = df_train[important_features].values\n",
    "    y = df_train[\"failureType_num\"].values\n",
    "\n",
    "# 6. Re-do train/validation split\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 7. Re-fit scaler ONLY on training set (NO LEAKAGE)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_valid = scaler.transform(X_valid_raw)\n",
    "\n",
    "print(\"\\nShapes after feature selection:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_valid:\", X_valid.shape)\n",
    "\n",
    "# 8. Refit the model with early stopping using the selected features\n",
    "if best_name == \"XGBoost\":\n",
    "    best_model.set_params(\n",
    "        early_stopping_rounds=20,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    print(\"Refitting XGBoost with early stopping on selected features...\")\n",
    "    best_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "# 9. Evaluate again\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_valid = best_model.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred_valid)\n",
    "\n",
    "print(\"\\n=== Per-Class Accuracy (AFTER Feature Selection) ===\")\n",
    "for cls_id in range(len(int2string)):\n",
    "    correct = cm[cls_id, cls_id]\n",
    "    total = cm[cls_id].sum()\n",
    "    acc = correct / total if total else 0\n",
    "    print(f\"{int2string[cls_id]:<10} : {acc:.4f} ({correct}/{total})\")\n",
    "\n",
    "print(f\"Total validation accuracy: {np.trace(cm) / np.sum(cm):.4f}\")\n",
    "# ============================================================\n",
    "# === 10. REBUILD TEST DATA USING SAME FEATURE SELECTION ===\n",
    "# ============================================================\n",
    "\n",
    "X_test = df_test[important_features].values\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "pred_labels = [int2string[i] for i in pred_test]\n",
    "pd.DataFrame({\"failureType\": pred_labels}).to_csv(\"scores.csv\", index=False)\n",
    "print(\"scores.csv saved with selected features!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy compared with Tree: 82.68%\n",
      "Accuracy compared with SVC: 91.47%\n"
     ]
    }
   ],
   "source": [
    "def compare_line_by_line(file1, file2):\n",
    "    with open(file1, 'r') as f1:\n",
    "        lines1 = f1.readlines()\n",
    "    with open(file2, 'r') as f2:\n",
    "        lines2 = f2.readlines()\n",
    "\n",
    "\n",
    "    if len(lines1) != len(lines2):\n",
    "        print(f\"Warning: Files have different number of lines ({len(lines1)} vs {len(lines2)})\")\n",
    "\n",
    "    if len(lines1) != 2027 or len(lines2) != 2027:\n",
    "        print(\"Warning: One or both files do not have 2028 lines as expected.\")\n",
    "        \n",
    "    matches = 0\n",
    "    for i in range(2027):\n",
    "        line1 = lines1[i].strip() \n",
    "        line2 = lines2[i].strip()\n",
    "\n",
    "        if line1 == line2:\n",
    "            matches += 1\n",
    "\n",
    "    similarity = (matches / 2027) * 100\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "acc = compare_line_by_line(\"scores.csv\", \"dt_scores.csv\")\n",
    "print(f\"Accuracy compared with Tree: {acc:.2f}%\") #should be around 81%\n",
    "\n",
    "acc = compare_line_by_line(\"scores.csv\", \"svc_scores.csv\")\n",
    "print(f\"Accuracy compared with SVC: {acc:.2f}%\") #should be around 90.23%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy compared with Tree: 83.72%\n",
      "Accuracy compared with SVC: 91.66%\n"
     ]
    }
   ],
   "source": [
    "acc = compare_line_by_line(\"scores_sub.csv\", \"dt_scores.csv\")\n",
    "print(f\"Accuracy compared with Tree: {acc:.2f}%\") #should be around 81%\n",
    "\n",
    "acc = compare_line_by_line(\"scores_sub.csv\", \"svc_scores.csv\")\n",
    "print(f\"Accuracy compared with SVC: {acc:.2f}%\") #should be around 90.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy compared with other model: 95.51%\n"
     ]
    }
   ],
   "source": [
    "acc = compare_line_by_line(\"scores_sub.csv\", \"scores.csv\")\n",
    "print(f\"Accuracy compared with other model: {acc:.2f}%\") #should be around 90.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. IMPORTS (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(X_train, y_train):\n",
    "    print(\"\\n============================\")\n",
    "    print(\"  Randomized Search  LightGBM\")\n",
    "    print(\"============================\")\n",
    "\n",
    "    lgbm = LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [300, 500, 700, 900],\n",
    "        \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "        \"num_leaves\": [31, 63, 127, 255],\n",
    "        \"max_depth\": [-1, 5, 7, 10],\n",
    "        \"min_child_samples\": [10, 20, 40],\n",
    "        \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
    "        \"reg_lambda\": [0.5, 1.0, 2.0],\n",
    "        \"min_split_gain\": [0.0, 0.1, 0.3],\n",
    "    }\n",
    "\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=40,                 # ~15 minutes\n",
    "        scoring=\"accuracy\",\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=10\n",
    "    )\n",
    "\n",
    "    rs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest LightGBM params:\")\n",
    "    print(rs.best_params_)\n",
    "    print(f\"Validation Accuracy: {rs.best_score_:.4f}\")\n",
    "\n",
    "    best_lgbm = rs.best_estimator_\n",
    "    return best_lgbm, rs.best_params_, rs.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "  Randomized Search  LightGBM\n",
      "============================\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "\n",
      "Best LightGBM params:\n",
      "{'subsample': 1.0, 'reg_lambda': 0.5, 'reg_alpha': 0, 'num_leaves': 63, 'n_estimators': 900, 'min_split_gain': 0.0, 'min_child_samples': 40, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "Validation Accuracy: 0.9800\n",
      "\n",
      "=== Training best LightGBM on FULL TRAIN SET ===\n",
      "\n",
      "Validation Accuracy (Full Model): 0.9727\n",
      "\n",
      "Test predictions saved in df_test['pred_full']\n"
     ]
    }
   ],
   "source": [
    "best_lgbm, best_params, best_cv_score = tune_lgbm(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Training best LightGBM on FULL TRAIN SET ===\")\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Validation accuracy\n",
    "y_pred_valid = best_lgbm.predict(X_valid)\n",
    "valid_acc = accuracy_score(y_valid, y_pred_valid)\n",
    "print(f\"\\nValidation Accuracy (Full Model): {valid_acc:.4f}\")\n",
    "\n",
    "# Test prediction\n",
    "try:\n",
    "    y_pred_test = best_lgbm.predict(X_test_scaled)\n",
    "    df_test[\"pred_full\"] = [int2string[i] for i in y_pred_test]\n",
    "    print(\"\\nTest predictions saved in df_test['pred_full']\")\n",
    "except Exception as e:\n",
    "    print(\"Test set prediction failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LIGHTGBM FEATURE IMPORTANCES ===\n",
      "maxDistFromCenter          2389\n",
      "minDistFromCenter          2019\n",
      "circularVariance           2003\n",
      "solidity                   1966\n",
      "eccentricity               1707\n",
      "                           ... \n",
      "comp_norm_count              58\n",
      "radial_4                      0\n",
      "lineOrientationVariance       0\n",
      "convexityRatio                0\n",
      "elongation                    0\n",
      "Length: 66, dtype: int32\n",
      "\n",
      "Using LightGBM importance threshold = 5\n",
      "Keeping 62/66 features\n",
      "Kept features: ['maxDistFromCenter', 'minDistFromCenter', 'circularVariance', 'solidity', 'eccentricity', 'radial_0', 'radial_1', 'radial_3', 'ang_4', 'hough_angle_mean', 'ringQ3', 'radialCurvature', 'thinnessRatio', 'ringQ1', 'largestComponentRatio', 'lineLikeness', 'hough_angle_std', 'hough_avg_len', 'ringQ2', 'ringQ4', 'edgeYieldLoss', 'ang_15', 'ang_8', 'ang_0', 'ang_11', 'hough_max_len', 'houghLineStrength', 'ang_3', 'quadComp_Q1', 'glcm_contrast', 'quadComp_Q3', 'hough_num', 'glcm_energy', 'quadComp_Q2', 'ang_12', 'areaRatio', 'majorAxisRatio', 'minorAxisRatio', 'radial_2', 'ang_7', 'numComponents', 'ang_2', 'ang_14', 'ang_6', 'quadFail_Q1', 'quadComp_Q4', 'comp_std_size', 'radialSlope', 'ang_10', 'ang_5', 'ang_1', 'ang_13', 'quadFail_Q4', 'perimeterRatio', 'ang_9', 'comp_mean_size', 'aspectRatio', 'glcm_homogeneity', 'quadFail_Q2', 'yieldLoss', 'quadFail_Q3', 'comp_norm_count']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. FEATURE PRUNING BASED ON THRESHOLD\n",
    "# ============================================================\n",
    "\n",
    "importances = best_lgbm.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n=== LIGHTGBM FEATURE IMPORTANCES ===\")\n",
    "print(feat_imp)\n",
    "\n",
    "# ----------- SET YOUR THRESHOLD HERE -----------\n",
    "lgbm_thresh = 5     # Recommended: 310 depending on aggressiveness\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Keep features whose importance is >= threshold\n",
    "kept_features = feat_imp[feat_imp >= lgbm_thresh].index.tolist()\n",
    "\n",
    "print(f\"\\nUsing LightGBM importance threshold = {lgbm_thresh}\")\n",
    "print(f\"Keeping {len(kept_features)}/{len(feat_imp)} features\")\n",
    "print(\"Kept features:\", kept_features)\n",
    "\n",
    "# Convert feature names  indices in original feature_cols\n",
    "idxs = [feature_cols.index(f) for f in kept_features]\n",
    "\n",
    "# Build reduced datasets\n",
    "X_train_red = X_train_raw[:, idxs]\n",
    "X_valid_red = X_valid_raw[:, idxs]\n",
    "X_test_red = X_test_scaled[:, idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training LightGBM on Reduced Feature Set (Threshold) ===\n",
      "\n",
      "=== LightGBM Validation Accuracies ===\n",
      "Full features:    0.9727\n",
      "Reduced features: 0.9727\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. TRAIN LightGBM ON REDUCED FEATURE SET\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Training LightGBM on Reduced Feature Set (Threshold) ===\")\n",
    "\n",
    "reduced_lgbm = LGBMClassifier(\n",
    "    **best_params,\n",
    "    objective=\"multiclass\",\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "reduced_lgbm.fit(X_train_red, y_train)\n",
    "\n",
    "# Validation accuracy (reduced feature model)\n",
    "y_pred_valid_red = reduced_lgbm.predict(X_valid_red)\n",
    "valid_acc_red = accuracy_score(y_valid, y_pred_valid_red)\n",
    "\n",
    "print(\"\\n=== LightGBM Validation Accuracies ===\")\n",
    "print(f\"Full features:    {valid_acc:.4f}\")\n",
    "print(f\"Reduced features: {valid_acc_red:.4f}\")\n",
    "print(\"=======================================\\n\")\n",
    "\n",
    "# Optional test predictions\n",
    "try:\n",
    "    y_pred_test_red = reduced_lgbm.predict(X_test_red)\n",
    "    df_test[\"pred_lgbm_reduced\"] = [int2string[i] for i in y_pred_test_red]\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "     FINAL MODEL COMPARISON\n",
      "====================================\n",
      "Full LightGBM Validation Accuracy:     0.9727\n",
      "Reduced-Feature LightGBM Accuracy:     0.9727\n",
      "====================================\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n====================================\")\n",
    "print(\"     FINAL MODEL COMPARISON\")\n",
    "print(\"====================================\")\n",
    "print(f\"Full LightGBM Validation Accuracy:     {valid_acc:.4f}\")\n",
    "print(f\"Reduced-Feature LightGBM Accuracy:     {valid_acc_red:.4f}\")\n",
    "print(\"====================================\")\n",
    "print(\"Difference:\", valid_acc - valid_acc_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def tune_xgb(X_train, y_train):\n",
    "    print(\"\\n============================\")\n",
    "    print(\"  Randomized Search  XGBoost\")\n",
    "    print(\"============================\")\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        use_label_encoder=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [300, 400, 500, 700],\n",
    "        \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "        \"max_depth\": [3, 4, 5, 6, 8, 10],\n",
    "        \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"gamma\": [0, 0.1, 0.3, 0.5],\n",
    "        \"min_child_weight\": [1, 3, 5, 8],\n",
    "        \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
    "        \"reg_lambda\": [0.5, 1.0, 2.0],\n",
    "        \"max_bin\": [128, 256],\n",
    "        \"grow_policy\": [\"depthwise\", \"lossguide\"],\n",
    "    }\n",
    "\n",
    "    rs = RandomizedSearchCV(\n",
    "        xgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=40,              # FAST ~ 15 minutes\n",
    "        scoring=\"accuracy\",\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest XGBoost params:\")\n",
    "    print(rs.best_params_)\n",
    "    print(f\"Validation Accuracy: {rs.best_score_:.4f}\")\n",
    "\n",
    "    best_xgb = rs.best_estimator_\n",
    "    return best_xgb, rs.best_params_, rs.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "  Randomized Search  XGBoost\n",
      "============================\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "\n",
      "Best XGBoost params:\n",
      "{'subsample': 1.0, 'reg_lambda': 2.0, 'reg_alpha': 1.0, 'n_estimators': 700, 'min_child_weight': 8, 'max_depth': 3, 'max_bin': 128, 'learning_rate': 0.1, 'grow_policy': 'lossguide', 'gamma': 0.5, 'colsample_bytree': 1.0}\n",
      "Validation Accuracy: 0.3857\n",
      "\n",
      "=== Training XGBoost on FULL TRAIN SET ===\n",
      "\n",
      "Validation Accuracy (Full XGBoost Model): 0.4018\n",
      "Test predictions stored under df_test['pred_full_xgb']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. TRAIN FINAL XGBOOST MODEL\n",
    "# ============================================================\n",
    "\n",
    "best_xgb, best_params, best_cv_score = tune_xgb(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training XGBoost on FULL TRAIN SET ===\")\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Validation accuracy\n",
    "y_pred_valid = best_xgb.predict(X_valid)\n",
    "valid_acc = accuracy_score(y_valid, y_pred_valid)\n",
    "\n",
    "print(f\"\\nValidation Accuracy (Full XGBoost Model): {valid_acc:.4f}\")\n",
    "\n",
    "# Test predictions\n",
    "try:\n",
    "    y_pred_test = best_xgb.predict(X_test_scaled)\n",
    "    df_test[\"pred_full_xgb\"] = [int2string[i] for i in y_pred_test]\n",
    "    print(\"Test predictions stored under df_test['pred_full_xgb']\")\n",
    "except Exception as e:\n",
    "    print(\"Test prediction error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE IMPORTANCES ===\n",
      "radialCurvature      0.083350\n",
      "eccentricity         0.077521\n",
      "minDistFromCenter    0.077018\n",
      "maxDistFromCenter    0.065166\n",
      "comp_norm_count      0.054841\n",
      "                       ...   \n",
      "lineLikeness         0.001421\n",
      "hough_angle_std      0.001379\n",
      "quadComp_Q4          0.001186\n",
      "ang_14               0.001125\n",
      "radial_4             0.000000\n",
      "Length: 66, dtype: float32\n",
      "\n",
      "Using threshold = 0.01\n",
      "Keeping 27 of 66 features\n",
      "Selected features: ['radialCurvature', 'eccentricity', 'minDistFromCenter', 'maxDistFromCenter', 'comp_norm_count', 'aspectRatio', 'minorAxisRatio', 'radial_1', 'radial_0', 'thinnessRatio', 'yieldLoss', 'comp_std_size', 'elongation', 'areaRatio', 'radial_3', 'radialSlope', 'quadFail_Q4', 'ang_5', 'hough_num', 'majorAxisRatio', 'ringQ2', 'solidity', 'lineOrientationVariance', 'circularVariance', 'radial_2', 'edgeYieldLoss', 'perimeterRatio']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. FEATURE IMPORTANCE  THRESHOLD-BASED PRUNING\n",
    "# ============================================================\n",
    "\n",
    "importances = best_xgb.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n=== FEATURE IMPORTANCES ===\")\n",
    "print(feat_imp)\n",
    "\n",
    "# ----------- SET YOUR THRESHOLD HERE -----------\n",
    "importance_threshold = 0.01   # <=== adjust this (0.0050.02 usually good)\n",
    "# ----------------------------------------------\n",
    "\n",
    "kept_features = feat_imp[feat_imp >= importance_threshold].index.tolist()\n",
    "\n",
    "print(f\"\\nUsing threshold = {importance_threshold}\")\n",
    "print(f\"Keeping {len(kept_features)} of {len(feat_imp)} features\")\n",
    "print(\"Selected features:\", kept_features)\n",
    "\n",
    "# Convert names  column indices\n",
    "idxs = [feature_cols.index(f) for f in kept_features]\n",
    "\n",
    "# Slice datasets\n",
    "X_train_red = X_train_raw[:, idxs]\n",
    "X_valid_red = X_valid_raw[:, idxs]\n",
    "X_test_red = X_test_scaled[:, idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Reduced-Feature XGBoost (Threshold-Based) ===\n",
      "\n",
      "Reduced Feature Validation Accuracy: 0.9727\n",
      "\n",
      "======================================\n",
      "   XGBOOST THRESHOLD FEATURE COMPARISON\n",
      "======================================\n",
      "Full Model Validation Accuracy:      0.9782\n",
      "Reduced-Feature Validation Accuracy: 0.9727\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. TRAIN XGBOOST ON REDUCED FEATURE SET\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Training Reduced-Feature XGBoost (Threshold-Based) ===\")\n",
    "\n",
    "reduced_xgb = XGBClassifier(\n",
    "    **best_params,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "reduced_xgb.fit(X_train_red, y_train)\n",
    "\n",
    "# Validation accuracy\n",
    "y_pred_valid_red = reduced_xgb.predict(X_valid_red)\n",
    "valid_acc_red = accuracy_score(y_valid, y_pred_valid_red)\n",
    "\n",
    "print(f\"\\nReduced Feature Validation Accuracy: {valid_acc_red:.4f}\")\n",
    "\n",
    "# Test predictions\n",
    "try:\n",
    "    y_pred_test_red = reduced_xgb.predict(X_test_red)\n",
    "    df_test[\"pred_reduced_xgb\"] = [int2string[i] for i in y_pred_test_red]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\n======================================\")\n",
    "print(\"   XGBOOST THRESHOLD FEATURE COMPARISON\")\n",
    "print(\"======================================\")\n",
    "print(f\"Full Model Validation Accuracy:      {valid_acc:.4f}\")\n",
    "print(f\"Reduced-Feature Validation Accuracy: {valid_acc_red:.4f}\")\n",
    "print(\"======================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 01m 03s]\n",
      "val_accuracy: 0.9709091186523438\n",
      "\n",
      "Best val_accuracy So Far: 0.9800000190734863\n",
      "Total elapsed time: 00h 12m 24s\n",
      "\n",
      "======================\n",
      " Best Hyperparameters \n",
      "======================\n",
      "('num_conv_layers', 1)\n",
      "('filters', 96)\n",
      "('kernel_size', 5)\n",
      "('cnn_dense', 128)\n",
      "('feat_dense1', 128)\n",
      "('feat_dense2', 96)\n",
      "('merged_dense', 128)\n",
      "('dropout', 0.2)\n",
      "('lr', 0.01)\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\n",
      "===================================\n",
      "   FINAL VALIDATION ACCURACY\n",
      "===================================\n",
      "Validation Accuracy: 0.9800\n",
      "Confusion matrix:\n",
      "[[152   1   0   0   1]\n",
      " [  2  76   0   0   0]\n",
      " [  0   1 231   0   0]\n",
      " [  0   0   0   3   0]\n",
      " [  1   0   5   0  77]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#      HYPERPARAMETER TUNING FOR HYBRID CNN + FEATURE MODEL\n",
    "# ============================================================\n",
    "\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build Image + Feature Tensors\n",
    "# ------------------------------------------------------------\n",
    "X_img = np.stack(df_train[\"waferMap_resized\"]).astype(\"float32\")\n",
    "X_img = X_img.reshape((-1, 64, 64, 1))\n",
    "\n",
    "X_feat_raw = df_train[important_features].values\n",
    "\n",
    "imputer_hybrid = SimpleImputer(strategy=\"mean\")\n",
    "X_feat = imputer_hybrid.fit_transform(X_feat_raw)\n",
    "\n",
    "scaler_hybrid = StandardScaler()\n",
    "X_feat = scaler_hybrid.fit_transform(X_feat)\n",
    "\n",
    "y = df_train[\"failureType_num\"].values\n",
    "\n",
    "X_img_train, X_img_val, X_feat_train, X_feat_val, y_train, y_val = train_test_split(\n",
    "    X_img, X_feat, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "feature_dim = len(important_features)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Model Builder for KerasTuner\n",
    "# ------------------------------------------------------------\n",
    "def build_hybrid_model(hp):\n",
    "    # CNN Branch\n",
    "    img_in = Input(shape=(64, 64, 1))\n",
    "\n",
    "    x = img_in\n",
    "    num_conv = hp.Int(\"num_conv_layers\", min_value=1, max_value=3, step=1)\n",
    "    filters = hp.Choice(\"filters\", values=[32, 48, 64, 96])\n",
    "    \n",
    "    for i in range(num_conv):\n",
    "        x = layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=hp.Choice(\"kernel_size\", values=[3, 5]),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\"\n",
    "        )(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    cnn_out = layers.Dense(\n",
    "        hp.Choice(\"cnn_dense\", values=[32, 64, 128]), activation=\"relu\"\n",
    "    )(x)\n",
    "\n",
    "    # Feature Branch\n",
    "    feat_in = Input(shape=(feature_dim,))\n",
    "    y1 = layers.Dense(\n",
    "        hp.Choice(\"feat_dense1\", values=[64, 96, 128]), activation=\"relu\"\n",
    "    )(feat_in)\n",
    "    y1 = layers.Dense(\n",
    "        hp.Choice(\"feat_dense2\", values=[32, 64, 96]), activation=\"relu\"\n",
    "    )(y1)\n",
    "\n",
    "    # Merge\n",
    "    merged = layers.concatenate([cnn_out, y1])\n",
    "    z = layers.Dense(\n",
    "        hp.Choice(\"merged_dense\", values=[64, 96, 128]), activation=\"relu\"\n",
    "    )(merged)\n",
    "    z = layers.Dropout(hp.Choice(\"dropout\", values=[0.2, 0.3, 0.4]))(z)\n",
    "\n",
    "    out = layers.Dense(5, activation=\"softmax\")(z)\n",
    "\n",
    "    model = Model(inputs=[img_in, feat_in], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice(\"lr\", values=[1e-2, 5e-3, 1e-3, 5e-4])\n",
    "        ),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Hyperparameter Search\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_hybrid_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=12,            # ~1020 minutes CPU; change to 30 for best results\n",
    "    executions_per_trial=1,\n",
    "    directory=\"hybrid_search\",\n",
    "    project_name=\"wafer_cnn_hybrid\"\n",
    ")\n",
    "\n",
    "print(\"Starting search\")\n",
    "tuner.search(\n",
    "    [X_img_train, X_feat_train],\n",
    "    y_train,\n",
    "    validation_data=([X_img_val, X_feat_val], y_val),\n",
    "    epochs=12,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Retrieve Best Model\n",
    "# ------------------------------------------------------------\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\" Best Hyperparameters \")\n",
    "print(\"======================\")\n",
    "for p in best_hp.values.items():\n",
    "    print(p)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Evaluate on Validation Set\n",
    "# ------------------------------------------------------------\n",
    "pred_val = np.argmax(\n",
    "    best_model.predict([X_img_val, X_feat_val]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "val_acc = accuracy_score(y_val, pred_val)\n",
    "print(\"\\n===================================\")\n",
    "print(\"   FINAL VALIDATION ACCURACY\")\n",
    "print(\"===================================\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_val, pred_val))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (hw5_env)",
   "language": "python",
   "name": "hw5_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
